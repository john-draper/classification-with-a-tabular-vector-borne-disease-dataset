{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fae6630",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "I would like to share my humble Kaggle competition Season 3 Episode 12 entry project with you, which aims to address the challenge of binary classification using a kidney stone prediction dataset. This project serves as a way for me to practice and improve my skills in ML/Data Science.\n",
    "\n",
    "Shortcomings aside, I hope it can demonstrate my growing capability in this field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aec214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "import csv\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from pygam import LogisticGAM\n",
    "#from pygam import LogisticGAM, s\n",
    "#import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5edfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data prep, decision tree, keras tensorflow predictor, evaluate with CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bd70d",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf5dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the file paths using os.path.join\n",
    "train_path = os.path.join(\"input\", \"train.csv\")\n",
    "test_path = os.path.join(\"input\", \"test.csv\")\n",
    "sample_submission_path = os.path.join(\"input\", \"sample_submission.csv\")\n",
    "\n",
    "# load the CSV data using pandas\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "sample_submission_data = pd.read_csv(sample_submission_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ca190",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d5d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  sudden_fever    headache  mouth_bleed  nose_bleed  \\\n",
      "count  707.000000    707.000000  707.000000   707.000000  707.000000   \n",
      "mean   353.000000      0.503536    0.449788     0.459689    0.487977   \n",
      "std    204.237607      0.500341    0.497825     0.498725    0.500209   \n",
      "min      0.000000      0.000000    0.000000     0.000000    0.000000   \n",
      "25%    176.500000      0.000000    0.000000     0.000000    0.000000   \n",
      "50%    353.000000      1.000000    0.000000     0.000000    0.000000   \n",
      "75%    529.500000      1.000000    1.000000     1.000000    1.000000   \n",
      "max    706.000000      1.000000    1.000000     1.000000    1.000000   \n",
      "\n",
      "       muscle_pain  joint_pain    vomiting        rash    diarrhea  ...  \\\n",
      "count   707.000000  707.000000  707.000000  707.000000  707.000000  ...   \n",
      "mean      0.517680    0.449788    0.441301    0.487977    0.390382  ...   \n",
      "std       0.500041    0.497825    0.496894    0.500209    0.488181  ...   \n",
      "min       0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "25%       0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "50%       1.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "75%       1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
      "max       1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
      "\n",
      "       lymph_swells  breathing_restriction  toe_inflammation  \\\n",
      "count    707.000000             707.000000        707.000000   \n",
      "mean       0.148515               0.072136          0.097595   \n",
      "std        0.355861               0.258896          0.296977   \n",
      "min        0.000000               0.000000          0.000000   \n",
      "25%        0.000000               0.000000          0.000000   \n",
      "50%        0.000000               0.000000          0.000000   \n",
      "75%        0.000000               0.000000          0.000000   \n",
      "max        1.000000               1.000000          1.000000   \n",
      "\n",
      "       finger_inflammation  lips_irritation   itchiness      ulcers  \\\n",
      "count           707.000000       707.000000  707.000000  707.000000   \n",
      "mean              0.079208         0.084866    0.154173    0.144272   \n",
      "std               0.270254         0.278879    0.361370    0.351614   \n",
      "min               0.000000         0.000000    0.000000    0.000000   \n",
      "25%               0.000000         0.000000    0.000000    0.000000   \n",
      "50%               0.000000         0.000000    0.000000    0.000000   \n",
      "75%               0.000000         0.000000    0.000000    0.000000   \n",
      "max               1.000000         1.000000    1.000000    1.000000   \n",
      "\n",
      "       toenail_loss  speech_problem  bullseye_rash  \n",
      "count    707.000000      707.000000     707.000000  \n",
      "mean       0.137199        0.032532       0.031117  \n",
      "std        0.344301        0.177533       0.173758  \n",
      "min        0.000000        0.000000       0.000000  \n",
      "25%        0.000000        0.000000       0.000000  \n",
      "50%        0.000000        0.000000       0.000000  \n",
      "75%        0.000000        0.000000       0.000000  \n",
      "max        1.000000        1.000000       1.000000  \n",
      "\n",
      "[8 rows x 65 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 707 entries, 0 to 706\n",
      "Data columns (total 66 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     707 non-null    int64  \n",
      " 1   sudden_fever           707 non-null    float64\n",
      " 2   headache               707 non-null    float64\n",
      " 3   mouth_bleed            707 non-null    float64\n",
      " 4   nose_bleed             707 non-null    float64\n",
      " 5   muscle_pain            707 non-null    float64\n",
      " 6   joint_pain             707 non-null    float64\n",
      " 7   vomiting               707 non-null    float64\n",
      " 8   rash                   707 non-null    float64\n",
      " 9   diarrhea               707 non-null    float64\n",
      " 10  hypotension            707 non-null    float64\n",
      " 11  pleural_effusion       707 non-null    float64\n",
      " 12  ascites                707 non-null    float64\n",
      " 13  gastro_bleeding        707 non-null    float64\n",
      " 14  swelling               707 non-null    float64\n",
      " 15  nausea                 707 non-null    float64\n",
      " 16  chills                 707 non-null    float64\n",
      " 17  myalgia                707 non-null    float64\n",
      " 18  digestion_trouble      707 non-null    float64\n",
      " 19  fatigue                707 non-null    float64\n",
      " 20  skin_lesions           707 non-null    float64\n",
      " 21  stomach_pain           707 non-null    float64\n",
      " 22  orbital_pain           707 non-null    float64\n",
      " 23  neck_pain              707 non-null    float64\n",
      " 24  weakness               707 non-null    float64\n",
      " 25  back_pain              707 non-null    float64\n",
      " 26  weight_loss            707 non-null    float64\n",
      " 27  gum_bleed              707 non-null    float64\n",
      " 28  jaundice               707 non-null    float64\n",
      " 29  coma                   707 non-null    float64\n",
      " 30  diziness               707 non-null    float64\n",
      " 31  inflammation           707 non-null    float64\n",
      " 32  red_eyes               707 non-null    float64\n",
      " 33  loss_of_appetite       707 non-null    float64\n",
      " 34  urination_loss         707 non-null    float64\n",
      " 35  slow_heart_rate        707 non-null    float64\n",
      " 36  abdominal_pain         707 non-null    float64\n",
      " 37  light_sensitivity      707 non-null    float64\n",
      " 38  yellow_skin            707 non-null    float64\n",
      " 39  yellow_eyes            707 non-null    float64\n",
      " 40  facial_distortion      707 non-null    float64\n",
      " 41  microcephaly           707 non-null    float64\n",
      " 42  rigor                  707 non-null    float64\n",
      " 43  bitter_tongue          707 non-null    float64\n",
      " 44  convulsion             707 non-null    float64\n",
      " 45  anemia                 707 non-null    float64\n",
      " 46  cocacola_urine         707 non-null    float64\n",
      " 47  hypoglycemia           707 non-null    float64\n",
      " 48  prostraction           707 non-null    float64\n",
      " 49  hyperpyrexia           707 non-null    float64\n",
      " 50  stiff_neck             707 non-null    float64\n",
      " 51  irritability           707 non-null    float64\n",
      " 52  confusion              707 non-null    float64\n",
      " 53  tremor                 707 non-null    float64\n",
      " 54  paralysis              707 non-null    float64\n",
      " 55  lymph_swells           707 non-null    float64\n",
      " 56  breathing_restriction  707 non-null    float64\n",
      " 57  toe_inflammation       707 non-null    float64\n",
      " 58  finger_inflammation    707 non-null    float64\n",
      " 59  lips_irritation        707 non-null    float64\n",
      " 60  itchiness              707 non-null    float64\n",
      " 61  ulcers                 707 non-null    float64\n",
      " 62  toenail_loss           707 non-null    float64\n",
      " 63  speech_problem         707 non-null    float64\n",
      " 64  bullseye_rash          707 non-null    float64\n",
      " 65  prognosis              707 non-null    object \n",
      "dtypes: float64(64), int64(1), object(1)\n",
      "memory usage: 364.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#prognosis is target\n",
    "\n",
    "#train_data.iloc[0].transform\n",
    "print(train_data.describe())\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44177458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>...</th>\n",
       "      <th>lymph_swells</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
       "0  707           0.0       0.0          0.0         0.0          0.0   \n",
       "1  708           1.0       1.0          0.0         1.0          0.0   \n",
       "2  709           1.0       1.0          0.0         1.0          1.0   \n",
       "3  710           0.0       1.0          0.0         0.0          0.0   \n",
       "4  711           0.0       0.0          1.0         0.0          1.0   \n",
       "\n",
       "   joint_pain  vomiting  rash  diarrhea  ...  lymph_swells  \\\n",
       "0         0.0       0.0   0.0       0.0  ...           0.0   \n",
       "1         1.0       1.0   1.0       1.0  ...           0.0   \n",
       "2         1.0       1.0   0.0       1.0  ...           0.0   \n",
       "3         1.0       1.0   1.0       0.0  ...           0.0   \n",
       "4         1.0       0.0   0.0       1.0  ...           0.0   \n",
       "\n",
       "   breathing_restriction  toe_inflammation  finger_inflammation  \\\n",
       "0                    0.0               0.0                  0.0   \n",
       "1                    0.0               0.0                  0.0   \n",
       "2                    0.0               0.0                  0.0   \n",
       "3                    0.0               0.0                  0.0   \n",
       "4                    0.0               0.0                  0.0   \n",
       "\n",
       "   lips_irritation  itchiness  ulcers  toenail_loss  speech_problem  \\\n",
       "0              0.0        0.0     0.0           0.0             0.0   \n",
       "1              0.0        0.0     0.0           0.0             0.0   \n",
       "2              0.0        1.0     0.0           0.0             0.0   \n",
       "3              0.0        0.0     0.0           0.0             0.0   \n",
       "4              0.0        0.0     0.0           0.0             0.0   \n",
       "\n",
       "   bullseye_rash  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c803a9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train_data\n",
    "y = X.pop('prognosis')\n",
    "#X for final data that is used to make prediction: test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68cda56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lyme_disease', 'Tungiasis', 'Zika', 'Rift_Valley_fever',\n",
       "       'West_Nile_fever', 'Malaria', 'Chikungunya', 'Plague', 'Dengue',\n",
       "       'Yellow_Fever', 'Japanese_encephalitis'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5d3d2",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3d0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a019169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables\n",
    "#variables = ['gravity','ph','osmo','cond','urea','calc']\n",
    "#variables = ['calc','urea']\n",
    "\n",
    "#train_X = train_data[variables]\n",
    "#train_y = train_data['prognosis']\n",
    "#val_X = test_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980f509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from https://www.kaggle.com/competitions/playground-series-s3e12/discussion/400005\n",
    "#X = train_data[['gravity', 'ph', 'cond', 'urea', 'calc']].copy()\n",
    "#Y = train_data['target']\n",
    "\n",
    "#Y = train_data['target']\n",
    "\n",
    "#Clipping  calc and gravity seems like it could be helpful, but in practice gives a worse validation score due to underfitting.\n",
    "#X['calc'] = X.calc.clip(None, 8)\n",
    "#X['gravity'] = X.gravity.clip(None, 1.03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b86c39",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3acff5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, testing, and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3667946f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479                   Dengue\n",
       "81           West_Nile_fever\n",
       "77           West_Nile_fever\n",
       "208    Japanese_encephalitis\n",
       "319        Rift_Valley_fever\n",
       "               ...          \n",
       "257              Chikungunya\n",
       "56                    Plague\n",
       "687          West_Nile_fever\n",
       "521                Tungiasis\n",
       "24              Lyme_disease\n",
       "Name: prognosis, Length: 142, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e43956",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "### Random Forest Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80ea03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a random forest classifier object\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "score = rf_model.score(X_test, y_test)\n",
    "\n",
    "X_test = test_data\n",
    "\n",
    "probabilities = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Get the top 3 classes with the highest probabilities for each example\n",
    "N = 3\n",
    "top_diseases = [probs.argsort()[-N:][::-1] for probs in probabilities]\n",
    "\n",
    "# Map the class indices to their corresponding labels\n",
    "disease_labels = rf_model.classes_\n",
    "top_labels = pd.DataFrame([[disease_labels[i] for i in classes] for classes in top_diseases])\n",
    "# Print the top 3 guesses for the first example\n",
    "#print(top_labels)\n",
    "rect_top_labels = pd.DataFrame(top_labels.apply(lambda row: ' '.join(row.astype(str)), axis=1))\n",
    "\n",
    "\n",
    "output = rect_top_labels.rename(columns={0: 'prognosis'})\n",
    "output['id'] = test_data.id\n",
    "output = output.set_index('id')\n",
    "output\n",
    "#output = pd.DataFrame({'id': test_data.id, 'prognosis': top_labels})\n",
    "\n",
    "\n",
    "output.to_csv('output/output.csv')#, quoting=csv.QUOTE_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e6cea",
   "metadata": {},
   "source": [
    "### DNN Model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7decc6b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>...</th>\n",
       "      <th>lymph_swells</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
       "404  404           1.0       1.0          1.0         0.0          0.0   \n",
       "59    59           0.0       1.0          0.0         0.0          0.0   \n",
       "36    36           0.0       0.0          0.0         0.0          1.0   \n",
       "182  182           0.0       0.0          0.0         1.0          0.0   \n",
       "571  571           0.0       1.0          1.0         0.0          1.0   \n",
       "..   ...           ...       ...          ...         ...          ...   \n",
       "552  552           1.0       0.0          0.0         0.0          0.0   \n",
       "626  626           1.0       0.0          1.0         0.0          1.0   \n",
       "477  477           0.0       0.0          0.0         0.0          0.0   \n",
       "473  473           1.0       0.0          0.0         0.0          0.0   \n",
       "338  338           0.0       1.0          0.0         0.0          1.0   \n",
       "\n",
       "     joint_pain  vomiting  rash  diarrhea  ...  lymph_swells  \\\n",
       "404         1.0       0.0   0.0       0.0  ...           0.0   \n",
       "59          0.0       1.0   0.0       0.0  ...           0.0   \n",
       "36          0.0       1.0   0.0       0.0  ...           0.0   \n",
       "182         0.0       0.0   1.0       1.0  ...           0.0   \n",
       "571         1.0       1.0   0.0       0.0  ...           0.0   \n",
       "..          ...       ...   ...       ...  ...           ...   \n",
       "552         0.0       0.0   1.0       0.0  ...           0.0   \n",
       "626         1.0       1.0   1.0       1.0  ...           1.0   \n",
       "477         0.0       1.0   0.0       1.0  ...           0.0   \n",
       "473         0.0       0.0   1.0       1.0  ...           0.0   \n",
       "338         1.0       1.0   1.0       1.0  ...           0.0   \n",
       "\n",
       "     breathing_restriction  toe_inflammation  finger_inflammation  \\\n",
       "404                    0.0               0.0                  0.0   \n",
       "59                     0.0               0.0                  0.0   \n",
       "36                     0.0               0.0                  0.0   \n",
       "182                    0.0               0.0                  0.0   \n",
       "571                    0.0               0.0                  0.0   \n",
       "..                     ...               ...                  ...   \n",
       "552                    0.0               0.0                  0.0   \n",
       "626                    0.0               0.0                  0.0   \n",
       "477                    0.0               0.0                  0.0   \n",
       "473                    0.0               0.0                  0.0   \n",
       "338                    0.0               0.0                  0.0   \n",
       "\n",
       "     lips_irritation  itchiness  ulcers  toenail_loss  speech_problem  \\\n",
       "404              0.0        0.0     0.0           0.0             0.0   \n",
       "59               0.0        0.0     0.0           0.0             0.0   \n",
       "36               0.0        1.0     1.0           1.0             0.0   \n",
       "182              0.0        1.0     1.0           1.0             0.0   \n",
       "571              0.0        0.0     0.0           0.0             0.0   \n",
       "..               ...        ...     ...           ...             ...   \n",
       "552              0.0        0.0     0.0           0.0             0.0   \n",
       "626              0.0        0.0     0.0           0.0             0.0   \n",
       "477              0.0        0.0     0.0           0.0             0.0   \n",
       "473              0.0        0.0     0.0           0.0             0.0   \n",
       "338              0.0        0.0     0.0           0.0             0.0   \n",
       "\n",
       "     bullseye_rash  \n",
       "404            0.0  \n",
       "59             0.0  \n",
       "36             0.0  \n",
       "182            0.0  \n",
       "571            0.0  \n",
       "..             ...  \n",
       "552            0.0  \n",
       "626            0.0  \n",
       "477            0.0  \n",
       "473            0.0  \n",
       "338            0.0  \n",
       "\n",
       "[113 rows x 65 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db1e2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14e398d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._split.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87730ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_one_hot\n",
    "\n",
    "#X_train 452, y_train 452 X_test 303, y_test 1420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2bcc4300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Yellow_Fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Japanese_encephalitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Dengue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Chikungunya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Dengue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 prognosis\n",
       "404      Rift_Valley_fever\n",
       "59                    Zika\n",
       "36               Tungiasis\n",
       "182      Rift_Valley_fever\n",
       "571           Yellow_Fever\n",
       "..                     ...\n",
       "552  Japanese_encephalitis\n",
       "626                 Dengue\n",
       "477              Tungiasis\n",
       "473            Chikungunya\n",
       "338                 Dengue\n",
       "\n",
       "[113 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "889619d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 750us/step\n",
      "      id  sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
      "479  479           1.0       0.0          0.0         0.0          0.0   \n",
      "81    81           0.0       1.0          1.0         1.0          1.0   \n",
      "77    77           0.0       0.0          1.0         0.0          1.0   \n",
      "208  208           0.0       0.0          0.0         0.0          0.0   \n",
      "319  319           0.0       1.0          0.0         0.0          1.0   \n",
      "..   ...           ...       ...          ...         ...          ...   \n",
      "257  257           1.0       1.0          1.0         0.0          1.0   \n",
      "56    56           0.0       0.0          0.0         1.0          0.0   \n",
      "687  687           0.0       1.0          0.0         1.0          0.0   \n",
      "521  521           0.0       0.0          0.0         0.0          0.0   \n",
      "24    24           0.0       0.0          0.0         1.0          1.0   \n",
      "\n",
      "     joint_pain  vomiting  rash  diarrhea  ...  lymph_swells  \\\n",
      "479         1.0       0.0   1.0       0.0  ...           1.0   \n",
      "81          0.0       0.0   0.0       1.0  ...           0.0   \n",
      "77          0.0       0.0   0.0       0.0  ...           0.0   \n",
      "208         0.0       0.0   0.0       0.0  ...           0.0   \n",
      "319         1.0       1.0   1.0       0.0  ...           0.0   \n",
      "..          ...       ...   ...       ...  ...           ...   \n",
      "257         1.0       1.0   1.0       1.0  ...           0.0   \n",
      "56          0.0       0.0   0.0       1.0  ...           0.0   \n",
      "687         1.0       0.0   0.0       0.0  ...           0.0   \n",
      "521         0.0       0.0   0.0       0.0  ...           0.0   \n",
      "24          0.0       1.0   1.0       1.0  ...           0.0   \n",
      "\n",
      "     breathing_restriction  toe_inflammation  finger_inflammation  \\\n",
      "479                    0.0               0.0                  0.0   \n",
      "81                     0.0               0.0                  0.0   \n",
      "77                     0.0               0.0                  0.0   \n",
      "208                    0.0               0.0                  0.0   \n",
      "319                    0.0               0.0                  0.0   \n",
      "..                     ...               ...                  ...   \n",
      "257                    0.0               0.0                  0.0   \n",
      "56                     0.0               0.0                  0.0   \n",
      "687                    0.0               0.0                  0.0   \n",
      "521                    0.0               1.0                  0.0   \n",
      "24                     0.0               0.0                  0.0   \n",
      "\n",
      "     lips_irritation  itchiness  ulcers  toenail_loss  speech_problem  \\\n",
      "479              0.0        0.0     0.0           0.0             0.0   \n",
      "81               0.0        1.0     0.0           1.0             0.0   \n",
      "77               0.0        1.0     1.0           0.0             0.0   \n",
      "208              0.0        0.0     0.0           0.0             0.0   \n",
      "319              0.0        1.0     0.0           0.0             0.0   \n",
      "..               ...        ...     ...           ...             ...   \n",
      "257              0.0        0.0     0.0           0.0             0.0   \n",
      "56               0.0        0.0     0.0           0.0             0.0   \n",
      "687              0.0        0.0     0.0           0.0             0.0   \n",
      "521              0.0        1.0     1.0           1.0             0.0   \n",
      "24               0.0        0.0     0.0           0.0             0.0   \n",
      "\n",
      "     bullseye_rash  \n",
      "479            0.0  \n",
      "81             0.0  \n",
      "77             0.0  \n",
      "208            0.0  \n",
      "319            0.0  \n",
      "..             ...  \n",
      "257            0.0  \n",
      "56             0.0  \n",
      "687            0.0  \n",
      "521            0.0  \n",
      "24             0.0  \n",
      "\n",
      "[142 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Select top three diseases\n",
    "top_three = y_pred.argsort()[:, -3:][:, ::-1]\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee8a95f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  2  1]\n",
      " [ 8  6  7]\n",
      " [ 6  1  7]\n",
      " [ 2  9 10]\n",
      " [ 7  1  2]\n",
      " [ 7  1  6]\n",
      " [ 8  4  5]\n",
      " [ 8  6  7]\n",
      " [ 1  4  0]\n",
      " [ 8  5  9]\n",
      " [ 9  2 10]\n",
      " [ 8  9  2]\n",
      " [ 4  8  2]\n",
      " [ 5  8  3]\n",
      " [ 3  2  4]\n",
      " [ 0  1  5]\n",
      " [ 6  8  7]\n",
      " [ 1  2  9]\n",
      " [ 4  5  3]\n",
      " [ 4  8  2]\n",
      " [ 2  9  4]\n",
      " [ 0  1  5]\n",
      " [10  9  8]\n",
      " [ 8  2  6]\n",
      " [ 6  1  8]\n",
      " [ 6  9  2]\n",
      " [ 3  5  2]\n",
      " [ 5  3  8]\n",
      " [ 4  2  8]\n",
      " [ 2  8  5]\n",
      " [ 3  8 10]\n",
      " [ 0  1  5]\n",
      " [ 7  6  2]\n",
      " [ 2  8  6]\n",
      " [ 9 10  8]\n",
      " [ 8  3  5]\n",
      " [ 9  2 10]\n",
      " [ 9  2  8]\n",
      " [ 4  8  2]\n",
      " [ 7  2  1]\n",
      " [ 9  2  8]\n",
      " [ 4  8 10]\n",
      " [ 0  1  5]\n",
      " [ 3  5  8]\n",
      " [ 6  1  7]\n",
      " [10  9  6]\n",
      " [ 0  1  5]\n",
      " [ 6  7  2]\n",
      " [ 6 10  9]\n",
      " [ 3  4  8]\n",
      " [ 8  6  5]\n",
      " [ 1  8  6]\n",
      " [10  6  9]\n",
      " [ 8  3  4]\n",
      " [ 8  4  3]\n",
      " [ 1  8  7]\n",
      " [ 2  4  3]\n",
      " [ 8  6  1]\n",
      " [ 2  5  1]\n",
      " [ 7  6  8]\n",
      " [ 8  6  9]\n",
      " [ 7  1  6]\n",
      " [ 8  4  3]\n",
      " [ 0  1  5]\n",
      " [ 8  6  4]\n",
      " [ 0  9  6]\n",
      " [ 8  2  7]\n",
      " [ 6  7  1]\n",
      " [ 1  2  8]\n",
      " [ 8  9  5]\n",
      " [ 4  1  8]\n",
      " [ 5  2  4]\n",
      " [10  9  6]\n",
      " [ 9 10  2]\n",
      " [ 0  1  5]\n",
      " [ 7  6  1]\n",
      " [ 4  3  5]\n",
      " [ 8  6  1]\n",
      " [ 2  9  5]\n",
      " [ 8  2  5]\n",
      " [ 1  0  2]\n",
      " [ 8  6  7]\n",
      " [10  2  9]\n",
      " [ 3 10  7]\n",
      " [ 8  5  9]\n",
      " [ 8  1  6]\n",
      " [ 0  9  5]\n",
      " [ 5  8 10]\n",
      " [ 8  4  1]\n",
      " [ 8  3 10]\n",
      " [ 8 10  4]\n",
      " [ 9  2  6]\n",
      " [ 8 10  5]\n",
      " [ 7  1  6]\n",
      " [ 9  4  2]\n",
      " [ 8  6  2]\n",
      " [ 4  5  3]\n",
      " [ 1  0  4]\n",
      " [ 0  9  5]\n",
      " [ 0  1  5]\n",
      " [ 3  5  8]\n",
      " [ 7  6  1]\n",
      " [ 7  6  2]\n",
      " [ 7  1  6]\n",
      " [ 6 10  9]\n",
      " [ 1  8  2]\n",
      " [ 6  2  8]\n",
      " [ 5  3  2]\n",
      " [ 8  3 10]\n",
      " [ 4  8  2]\n",
      " [ 3  5  8]\n",
      " [10  4  8]\n",
      " [ 9  2 10]\n",
      " [ 8  1  2]\n",
      " [ 8 10  6]\n",
      " [ 8  1 10]\n",
      " [ 9  6  8]\n",
      " [10  6  9]\n",
      " [ 2  7  9]\n",
      " [ 1  6  7]\n",
      " [ 3  9 10]\n",
      " [10  7  9]\n",
      " [ 8 10  7]\n",
      " [ 3  5  8]\n",
      " [ 6  1  7]\n",
      " [ 9  2 10]\n",
      " [ 2  9  7]\n",
      " [ 4  8  2]\n",
      " [ 3 10  7]\n",
      " [ 5  3  9]\n",
      " [10  9  6]\n",
      " [ 1  6  7]\n",
      " [ 0  1  5]\n",
      " [ 5  3  9]\n",
      " [ 7  6  1]\n",
      " [ 5  1  0]\n",
      " [ 1  8  4]\n",
      " [ 0  1  5]\n",
      " [ 3  2  4]\n",
      " [ 9  8  5]\n",
      " [ 7  6  1]\n",
      " [ 9  4  8]]\n"
     ]
    }
   ],
   "source": [
    "print(top_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2058f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 44.0096 - accuracy: 0.1080 - val_loss: 10.7293 - val_accuracy: 0.0708\n",
      "Epoch 2/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 23.6633 - accuracy: 0.0743 - val_loss: 7.2762 - val_accuracy: 0.0885\n",
      "Epoch 3/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.3567 - accuracy: 0.0991 - val_loss: 2.7477 - val_accuracy: 0.0973\n",
      "Epoch 4/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8395 - accuracy: 0.0726 - val_loss: 2.7163 - val_accuracy: 0.0973\n",
      "Epoch 5/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.4378 - accuracy: 0.0903 - val_loss: 2.6924 - val_accuracy: 0.0973\n",
      "Epoch 6/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.1704 - accuracy: 0.0938 - val_loss: 2.6743 - val_accuracy: 0.0973\n",
      "Epoch 7/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.8894 - accuracy: 0.0956 - val_loss: 2.6605 - val_accuracy: 0.0973\n",
      "Epoch 8/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.8572 - accuracy: 0.1044 - val_loss: 2.6502 - val_accuracy: 0.0973\n",
      "Epoch 9/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7979 - accuracy: 0.0920 - val_loss: 2.6423 - val_accuracy: 0.1150\n",
      "Epoch 10/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7373 - accuracy: 0.1062 - val_loss: 2.6366 - val_accuracy: 0.1150\n",
      "Epoch 11/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7667 - accuracy: 0.1009 - val_loss: 2.6324 - val_accuracy: 0.1150\n",
      "Epoch 12/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7173 - accuracy: 0.1115 - val_loss: 2.6292 - val_accuracy: 0.1150\n",
      "Epoch 13/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7263 - accuracy: 0.1150 - val_loss: 2.6267 - val_accuracy: 0.1150\n",
      "Epoch 14/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6670 - accuracy: 0.1115 - val_loss: 2.6246 - val_accuracy: 0.1150\n",
      "Epoch 15/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7203 - accuracy: 0.1204 - val_loss: 2.6229 - val_accuracy: 0.1150\n",
      "Epoch 16/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6964 - accuracy: 0.1168 - val_loss: 2.6215 - val_accuracy: 0.1150\n",
      "Epoch 17/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6425 - accuracy: 0.1115 - val_loss: 2.6202 - val_accuracy: 0.1150\n",
      "Epoch 18/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6238 - accuracy: 0.1133 - val_loss: 2.6190 - val_accuracy: 0.1150\n",
      "Epoch 19/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6593 - accuracy: 0.1080 - val_loss: 2.6179 - val_accuracy: 0.1150\n",
      "Epoch 20/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6230 - accuracy: 0.1204 - val_loss: 2.6168 - val_accuracy: 0.1150\n",
      "Epoch 21/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6528 - accuracy: 0.1080 - val_loss: 2.6159 - val_accuracy: 0.1150\n",
      "Epoch 22/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6563 - accuracy: 0.1062 - val_loss: 2.6149 - val_accuracy: 0.1150\n",
      "Epoch 23/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6264 - accuracy: 0.1115 - val_loss: 2.6140 - val_accuracy: 0.1150\n",
      "Epoch 24/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6150 - accuracy: 0.1133 - val_loss: 2.6131 - val_accuracy: 0.1150\n",
      "Epoch 25/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6133 - accuracy: 0.1133 - val_loss: 2.6121 - val_accuracy: 0.1150\n",
      "Epoch 26/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6096 - accuracy: 0.1150 - val_loss: 2.6112 - val_accuracy: 0.1150\n",
      "Epoch 27/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6211 - accuracy: 0.1133 - val_loss: 2.6102 - val_accuracy: 0.1150\n",
      "Epoch 28/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6178 - accuracy: 0.1133 - val_loss: 2.6095 - val_accuracy: 0.1150\n",
      "Epoch 29/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6198 - accuracy: 0.1133 - val_loss: 2.6086 - val_accuracy: 0.1150\n",
      "Epoch 30/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6104 - accuracy: 0.1133 - val_loss: 2.6077 - val_accuracy: 0.1150\n",
      "Epoch 31/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6452 - accuracy: 0.1115 - val_loss: 2.6070 - val_accuracy: 0.1150\n",
      "Epoch 32/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6178 - accuracy: 0.1150 - val_loss: 2.6062 - val_accuracy: 0.1150\n",
      "Epoch 33/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6131 - accuracy: 0.1186 - val_loss: 2.6052 - val_accuracy: 0.1150\n",
      "Epoch 34/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6141 - accuracy: 0.1150 - val_loss: 2.6047 - val_accuracy: 0.1150\n",
      "Epoch 35/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6055 - accuracy: 0.1168 - val_loss: 2.6039 - val_accuracy: 0.1150\n",
      "Epoch 36/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5997 - accuracy: 0.1150 - val_loss: 2.6030 - val_accuracy: 0.1150\n",
      "Epoch 37/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6034 - accuracy: 0.1186 - val_loss: 2.6022 - val_accuracy: 0.1150\n",
      "Epoch 38/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5992 - accuracy: 0.1186 - val_loss: 2.6014 - val_accuracy: 0.1150\n",
      "Epoch 39/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5985 - accuracy: 0.1168 - val_loss: 2.6004 - val_accuracy: 0.1150\n",
      "Epoch 40/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6035 - accuracy: 0.1186 - val_loss: 2.5995 - val_accuracy: 0.1150\n",
      "Epoch 41/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6005 - accuracy: 0.1133 - val_loss: 2.5983 - val_accuracy: 0.1150\n",
      "Epoch 42/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5898 - accuracy: 0.1186 - val_loss: 2.5974 - val_accuracy: 0.1150\n",
      "Epoch 43/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6069 - accuracy: 0.1186 - val_loss: 2.5967 - val_accuracy: 0.1150\n",
      "Epoch 44/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5926 - accuracy: 0.1150 - val_loss: 2.5956 - val_accuracy: 0.1150\n",
      "Epoch 45/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5862 - accuracy: 0.1186 - val_loss: 2.5943 - val_accuracy: 0.1150\n",
      "Epoch 46/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5804 - accuracy: 0.1221 - val_loss: 2.5930 - val_accuracy: 0.1150\n",
      "Epoch 47/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5857 - accuracy: 0.1168 - val_loss: 2.5919 - val_accuracy: 0.1150\n",
      "Epoch 48/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5901 - accuracy: 0.1133 - val_loss: 2.5907 - val_accuracy: 0.1150\n",
      "Epoch 49/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5833 - accuracy: 0.1115 - val_loss: 2.5898 - val_accuracy: 0.1239\n",
      "Epoch 50/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5757 - accuracy: 0.1221 - val_loss: 2.5887 - val_accuracy: 0.1239\n",
      "Epoch 51/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5958 - accuracy: 0.1204 - val_loss: 2.5877 - val_accuracy: 0.1239\n",
      "Epoch 52/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5856 - accuracy: 0.1204 - val_loss: 2.5868 - val_accuracy: 0.1239\n",
      "Epoch 53/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5724 - accuracy: 0.1239 - val_loss: 2.5856 - val_accuracy: 0.1239\n",
      "Epoch 54/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5790 - accuracy: 0.1204 - val_loss: 2.5845 - val_accuracy: 0.1239\n",
      "Epoch 55/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5789 - accuracy: 0.1186 - val_loss: 2.5833 - val_accuracy: 0.1239\n",
      "Epoch 56/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5776 - accuracy: 0.1186 - val_loss: 2.5824 - val_accuracy: 0.1239\n",
      "Epoch 57/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5704 - accuracy: 0.1204 - val_loss: 2.5815 - val_accuracy: 0.1239\n",
      "Epoch 58/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5783 - accuracy: 0.1239 - val_loss: 2.5805 - val_accuracy: 0.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5873 - accuracy: 0.1204 - val_loss: 2.5798 - val_accuracy: 0.1239\n",
      "Epoch 60/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5710 - accuracy: 0.1204 - val_loss: 2.5788 - val_accuracy: 0.1239\n",
      "Epoch 61/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5664 - accuracy: 0.1221 - val_loss: 2.5779 - val_accuracy: 0.1239\n",
      "Epoch 62/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5659 - accuracy: 0.1204 - val_loss: 2.5769 - val_accuracy: 0.1239\n",
      "Epoch 63/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5594 - accuracy: 0.1257 - val_loss: 2.5756 - val_accuracy: 0.1239\n",
      "Epoch 64/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5582 - accuracy: 0.1204 - val_loss: 2.5745 - val_accuracy: 0.1239\n",
      "Epoch 65/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5581 - accuracy: 0.1274 - val_loss: 2.5734 - val_accuracy: 0.1239\n",
      "Epoch 66/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5624 - accuracy: 0.1221 - val_loss: 2.5721 - val_accuracy: 0.1239\n",
      "Epoch 67/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5633 - accuracy: 0.1204 - val_loss: 2.5715 - val_accuracy: 0.1239\n",
      "Epoch 68/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5717 - accuracy: 0.1204 - val_loss: 2.5703 - val_accuracy: 0.1239\n",
      "Epoch 69/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5685 - accuracy: 0.1204 - val_loss: 2.5694 - val_accuracy: 0.1239\n",
      "Epoch 70/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5591 - accuracy: 0.1204 - val_loss: 2.5686 - val_accuracy: 0.1239\n",
      "Epoch 71/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5617 - accuracy: 0.1221 - val_loss: 2.5699 - val_accuracy: 0.1239\n",
      "Epoch 72/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5567 - accuracy: 0.1221 - val_loss: 2.5733 - val_accuracy: 0.1239\n",
      "Epoch 73/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5612 - accuracy: 0.1239 - val_loss: 2.5773 - val_accuracy: 0.1239\n",
      "Epoch 74/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5614 - accuracy: 0.1221 - val_loss: 2.5675 - val_accuracy: 0.1239\n",
      "Epoch 75/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5484 - accuracy: 0.1239 - val_loss: 2.5694 - val_accuracy: 0.1239\n",
      "Epoch 76/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5473 - accuracy: 0.1221 - val_loss: 2.5648 - val_accuracy: 0.1239\n",
      "Epoch 77/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5498 - accuracy: 0.1257 - val_loss: 2.5646 - val_accuracy: 0.1239\n",
      "Epoch 78/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5569 - accuracy: 0.1221 - val_loss: 2.5649 - val_accuracy: 0.1239\n",
      "Epoch 79/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5521 - accuracy: 0.1204 - val_loss: 2.5620 - val_accuracy: 0.1239\n",
      "Epoch 80/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5441 - accuracy: 0.1204 - val_loss: 2.5612 - val_accuracy: 0.1239\n",
      "Epoch 81/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5491 - accuracy: 0.1221 - val_loss: 2.5599 - val_accuracy: 0.1239\n",
      "Epoch 82/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5491 - accuracy: 0.1221 - val_loss: 2.5596 - val_accuracy: 0.1239\n",
      "Epoch 83/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5433 - accuracy: 0.1257 - val_loss: 2.5592 - val_accuracy: 0.1239\n",
      "Epoch 84/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5404 - accuracy: 0.1274 - val_loss: 2.5600 - val_accuracy: 0.1239\n",
      "Epoch 85/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5388 - accuracy: 0.1257 - val_loss: 2.5586 - val_accuracy: 0.1239\n",
      "Epoch 86/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5388 - accuracy: 0.1257 - val_loss: 2.5568 - val_accuracy: 0.1239\n",
      "Epoch 87/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5437 - accuracy: 0.1221 - val_loss: 2.5537 - val_accuracy: 0.1239\n",
      "Epoch 88/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5347 - accuracy: 0.1239 - val_loss: 2.5534 - val_accuracy: 0.1239\n",
      "Epoch 89/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5376 - accuracy: 0.1239 - val_loss: 2.5529 - val_accuracy: 0.1239\n",
      "Epoch 90/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5392 - accuracy: 0.1239 - val_loss: 2.5539 - val_accuracy: 0.1239\n",
      "Epoch 91/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5335 - accuracy: 0.1257 - val_loss: 2.5538 - val_accuracy: 0.1239\n",
      "Epoch 92/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5347 - accuracy: 0.1239 - val_loss: 2.5631 - val_accuracy: 0.1239\n",
      "Epoch 93/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5360 - accuracy: 0.1257 - val_loss: 2.5482 - val_accuracy: 0.1239\n",
      "Epoch 94/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5378 - accuracy: 0.1239 - val_loss: 2.5463 - val_accuracy: 0.1239\n",
      "Epoch 95/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5389 - accuracy: 0.1204 - val_loss: 2.5460 - val_accuracy: 0.1239\n",
      "Epoch 96/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5418 - accuracy: 0.1239 - val_loss: 2.5473 - val_accuracy: 0.1239\n",
      "Epoch 97/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5314 - accuracy: 0.1239 - val_loss: 2.5467 - val_accuracy: 0.1239\n",
      "Epoch 98/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5383 - accuracy: 0.1239 - val_loss: 2.5464 - val_accuracy: 0.1239\n",
      "Epoch 99/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5349 - accuracy: 0.1204 - val_loss: 2.5539 - val_accuracy: 0.1239\n",
      "Epoch 100/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5306 - accuracy: 0.1257 - val_loss: 2.5485 - val_accuracy: 0.1239\n",
      "Epoch 101/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5209 - accuracy: 0.1239 - val_loss: 2.5428 - val_accuracy: 0.1239\n",
      "Epoch 102/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5272 - accuracy: 0.1221 - val_loss: 2.5424 - val_accuracy: 0.1239\n",
      "Epoch 103/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5200 - accuracy: 0.1239 - val_loss: 2.5424 - val_accuracy: 0.1239\n",
      "Epoch 104/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5301 - accuracy: 0.1186 - val_loss: 2.5473 - val_accuracy: 0.1239\n",
      "Epoch 105/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5187 - accuracy: 0.1239 - val_loss: 2.5436 - val_accuracy: 0.1239\n",
      "Epoch 106/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5224 - accuracy: 0.1221 - val_loss: 2.5419 - val_accuracy: 0.1239\n",
      "Epoch 107/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5213 - accuracy: 0.1221 - val_loss: 2.5447 - val_accuracy: 0.1239\n",
      "Epoch 108/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5244 - accuracy: 0.1204 - val_loss: 2.5427 - val_accuracy: 0.1239\n",
      "Epoch 109/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5257 - accuracy: 0.1239 - val_loss: 2.5435 - val_accuracy: 0.1239\n",
      "Epoch 110/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5167 - accuracy: 0.1239 - val_loss: 2.5477 - val_accuracy: 0.1239\n",
      "Epoch 111/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5161 - accuracy: 0.1292 - val_loss: 2.5527 - val_accuracy: 0.1239\n",
      "Epoch 112/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5373 - accuracy: 0.1257 - val_loss: 2.5346 - val_accuracy: 0.1239\n",
      "Epoch 113/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5188 - accuracy: 0.1221 - val_loss: 2.5298 - val_accuracy: 0.1239\n",
      "Epoch 114/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5123 - accuracy: 0.1239 - val_loss: 2.5286 - val_accuracy: 0.1239\n",
      "Epoch 115/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5173 - accuracy: 0.1186 - val_loss: 2.5273 - val_accuracy: 0.1239\n",
      "Epoch 116/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5204 - accuracy: 0.1221 - val_loss: 2.5261 - val_accuracy: 0.1239\n",
      "Epoch 117/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5140 - accuracy: 0.1257 - val_loss: 2.5258 - val_accuracy: 0.1239\n",
      "Epoch 118/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5172 - accuracy: 0.1221 - val_loss: 2.5261 - val_accuracy: 0.1239\n",
      "Epoch 119/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5084 - accuracy: 0.1257 - val_loss: 2.5272 - val_accuracy: 0.1239\n",
      "Epoch 120/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5221 - accuracy: 0.1239 - val_loss: 2.5248 - val_accuracy: 0.1239\n",
      "Epoch 121/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5037 - accuracy: 0.1239 - val_loss: 2.5267 - val_accuracy: 0.1239\n",
      "Epoch 122/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5144 - accuracy: 0.1168 - val_loss: 2.5245 - val_accuracy: 0.1239\n",
      "Epoch 123/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5025 - accuracy: 0.1257 - val_loss: 2.5233 - val_accuracy: 0.1239\n",
      "Epoch 124/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5043 - accuracy: 0.1239 - val_loss: 2.5223 - val_accuracy: 0.1239\n",
      "Epoch 125/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5068 - accuracy: 0.1239 - val_loss: 2.5214 - val_accuracy: 0.1239\n",
      "Epoch 126/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5027 - accuracy: 0.1239 - val_loss: 2.5206 - val_accuracy: 0.1239\n",
      "Epoch 127/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5074 - accuracy: 0.1221 - val_loss: 2.5226 - val_accuracy: 0.1239\n",
      "Epoch 128/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4994 - accuracy: 0.1239 - val_loss: 2.5229 - val_accuracy: 0.1239\n",
      "Epoch 129/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5040 - accuracy: 0.1257 - val_loss: 2.5220 - val_accuracy: 0.1239\n",
      "Epoch 130/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4980 - accuracy: 0.1239 - val_loss: 2.5196 - val_accuracy: 0.1239\n",
      "Epoch 131/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4973 - accuracy: 0.1274 - val_loss: 2.5212 - val_accuracy: 0.1239\n",
      "Epoch 132/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4891 - accuracy: 0.1239 - val_loss: 2.5232 - val_accuracy: 0.1239\n",
      "Epoch 133/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4960 - accuracy: 0.1239 - val_loss: 2.5248 - val_accuracy: 0.1239\n",
      "Epoch 134/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4924 - accuracy: 0.1257 - val_loss: 2.5264 - val_accuracy: 0.1239\n",
      "Epoch 135/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4976 - accuracy: 0.1239 - val_loss: 2.5166 - val_accuracy: 0.1239\n",
      "Epoch 136/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4939 - accuracy: 0.1239 - val_loss: 2.5147 - val_accuracy: 0.1239\n",
      "Epoch 137/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4998 - accuracy: 0.1239 - val_loss: 2.5143 - val_accuracy: 0.1239\n",
      "Epoch 138/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4868 - accuracy: 0.1257 - val_loss: 2.5200 - val_accuracy: 0.1239\n",
      "Epoch 139/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4924 - accuracy: 0.1257 - val_loss: 2.5177 - val_accuracy: 0.1239\n",
      "Epoch 140/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5040 - accuracy: 0.1257 - val_loss: 2.5137 - val_accuracy: 0.1239\n",
      "Epoch 141/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4884 - accuracy: 0.1239 - val_loss: 2.5149 - val_accuracy: 0.1239\n",
      "Epoch 142/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4897 - accuracy: 0.1204 - val_loss: 2.5160 - val_accuracy: 0.1239\n",
      "Epoch 143/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4838 - accuracy: 0.1239 - val_loss: 2.5160 - val_accuracy: 0.1239\n",
      "Epoch 144/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5129 - accuracy: 0.1274 - val_loss: 2.5167 - val_accuracy: 0.1239\n",
      "Epoch 145/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4793 - accuracy: 0.1239 - val_loss: 2.5160 - val_accuracy: 0.1239\n",
      "Epoch 146/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4894 - accuracy: 0.1239 - val_loss: 2.5121 - val_accuracy: 0.1239\n",
      "Epoch 147/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4809 - accuracy: 0.1257 - val_loss: 2.5157 - val_accuracy: 0.1239\n",
      "Epoch 148/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4827 - accuracy: 0.1292 - val_loss: 2.5075 - val_accuracy: 0.1239\n",
      "Epoch 149/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4986 - accuracy: 0.1221 - val_loss: 2.5148 - val_accuracy: 0.1239\n",
      "Epoch 150/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4781 - accuracy: 0.1257 - val_loss: 2.5148 - val_accuracy: 0.1239\n",
      "Epoch 151/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4761 - accuracy: 0.1274 - val_loss: 2.5094 - val_accuracy: 0.1239\n",
      "Epoch 152/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4778 - accuracy: 0.1292 - val_loss: 2.5043 - val_accuracy: 0.1239\n",
      "Epoch 153/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4862 - accuracy: 0.1274 - val_loss: 2.5051 - val_accuracy: 0.1239\n",
      "Epoch 154/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4700 - accuracy: 0.1274 - val_loss: 2.5070 - val_accuracy: 0.1239\n",
      "Epoch 155/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4835 - accuracy: 0.1221 - val_loss: 2.5078 - val_accuracy: 0.1239\n",
      "Epoch 156/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4851 - accuracy: 0.1221 - val_loss: 2.5091 - val_accuracy: 0.1239\n",
      "Epoch 157/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4779 - accuracy: 0.1239 - val_loss: 2.5013 - val_accuracy: 0.1239\n",
      "Epoch 158/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4741 - accuracy: 0.1274 - val_loss: 2.5014 - val_accuracy: 0.1239\n",
      "Epoch 159/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4739 - accuracy: 0.1239 - val_loss: 2.5027 - val_accuracy: 0.1239\n",
      "Epoch 160/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4692 - accuracy: 0.1274 - val_loss: 2.5011 - val_accuracy: 0.1239\n",
      "Epoch 161/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4680 - accuracy: 0.1239 - val_loss: 2.5006 - val_accuracy: 0.1239\n",
      "Epoch 162/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4651 - accuracy: 0.1257 - val_loss: 2.5014 - val_accuracy: 0.1239\n",
      "Epoch 163/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4688 - accuracy: 0.1239 - val_loss: 2.5041 - val_accuracy: 0.1239\n",
      "Epoch 164/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4659 - accuracy: 0.1257 - val_loss: 2.5049 - val_accuracy: 0.1239\n",
      "Epoch 165/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4737 - accuracy: 0.1239 - val_loss: 2.4943 - val_accuracy: 0.1239\n",
      "Epoch 166/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4641 - accuracy: 0.1292 - val_loss: 2.4958 - val_accuracy: 0.1239\n",
      "Epoch 167/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4777 - accuracy: 0.1274 - val_loss: 2.4955 - val_accuracy: 0.1239\n",
      "Epoch 168/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4692 - accuracy: 0.1274 - val_loss: 2.4966 - val_accuracy: 0.1239\n",
      "Epoch 169/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4561 - accuracy: 0.1274 - val_loss: 2.4945 - val_accuracy: 0.1239\n",
      "Epoch 170/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4569 - accuracy: 0.1274 - val_loss: 2.4927 - val_accuracy: 0.1239\n",
      "Epoch 171/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4535 - accuracy: 0.1274 - val_loss: 2.4940 - val_accuracy: 0.1239\n",
      "Epoch 172/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4587 - accuracy: 0.1239 - val_loss: 2.4895 - val_accuracy: 0.1239\n",
      "Epoch 173/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4549 - accuracy: 0.1274 - val_loss: 2.4895 - val_accuracy: 0.1239\n",
      "Epoch 174/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4535 - accuracy: 0.1292 - val_loss: 2.4915 - val_accuracy: 0.1239\n",
      "Epoch 175/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4552 - accuracy: 0.1257 - val_loss: 2.4908 - val_accuracy: 0.1239\n",
      "Epoch 176/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4539 - accuracy: 0.1274 - val_loss: 2.4872 - val_accuracy: 0.1239\n",
      "Epoch 177/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4593 - accuracy: 0.1257 - val_loss: 2.4858 - val_accuracy: 0.1239\n",
      "Epoch 178/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4579 - accuracy: 0.1274 - val_loss: 2.4868 - val_accuracy: 0.1239\n",
      "Epoch 179/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4557 - accuracy: 0.1274 - val_loss: 2.4873 - val_accuracy: 0.1239\n",
      "Epoch 180/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4542 - accuracy: 0.1274 - val_loss: 2.4857 - val_accuracy: 0.1239\n",
      "Epoch 181/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4483 - accuracy: 0.1274 - val_loss: 2.4829 - val_accuracy: 0.1239\n",
      "Epoch 182/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4473 - accuracy: 0.1274 - val_loss: 2.4859 - val_accuracy: 0.1239\n",
      "Epoch 183/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4525 - accuracy: 0.1274 - val_loss: 2.4860 - val_accuracy: 0.1239\n",
      "Epoch 184/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4452 - accuracy: 0.1274 - val_loss: 2.4810 - val_accuracy: 0.1239\n",
      "Epoch 185/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4441 - accuracy: 0.1292 - val_loss: 2.4843 - val_accuracy: 0.1239\n",
      "Epoch 186/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4434 - accuracy: 0.1274 - val_loss: 2.4889 - val_accuracy: 0.1239\n",
      "Epoch 187/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4459 - accuracy: 0.1239 - val_loss: 2.4961 - val_accuracy: 0.1239\n",
      "Epoch 188/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4416 - accuracy: 0.1257 - val_loss: 2.4821 - val_accuracy: 0.1239\n",
      "Epoch 189/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4403 - accuracy: 0.1257 - val_loss: 2.4823 - val_accuracy: 0.1239\n",
      "Epoch 190/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4479 - accuracy: 0.1257 - val_loss: 2.4800 - val_accuracy: 0.1239\n",
      "Epoch 191/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4415 - accuracy: 0.1274 - val_loss: 2.4803 - val_accuracy: 0.1239\n",
      "Epoch 192/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4434 - accuracy: 0.1292 - val_loss: 2.4804 - val_accuracy: 0.1239\n",
      "Epoch 193/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4480 - accuracy: 0.1239 - val_loss: 2.4776 - val_accuracy: 0.1239\n",
      "Epoch 194/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4384 - accuracy: 0.1239 - val_loss: 2.4762 - val_accuracy: 0.1239\n",
      "Epoch 195/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4396 - accuracy: 0.1257 - val_loss: 2.4780 - val_accuracy: 0.1239\n",
      "Epoch 196/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4374 - accuracy: 0.1292 - val_loss: 2.4758 - val_accuracy: 0.1239\n",
      "Epoch 197/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4367 - accuracy: 0.1221 - val_loss: 2.4765 - val_accuracy: 0.1239\n",
      "Epoch 198/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4375 - accuracy: 0.1274 - val_loss: 2.4744 - val_accuracy: 0.1239\n",
      "Epoch 199/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4298 - accuracy: 0.1274 - val_loss: 2.4708 - val_accuracy: 0.1239\n",
      "Epoch 200/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4326 - accuracy: 0.1292 - val_loss: 2.4716 - val_accuracy: 0.1239\n",
      "Epoch 201/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4327 - accuracy: 0.1274 - val_loss: 2.4730 - val_accuracy: 0.1239\n",
      "Epoch 202/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4293 - accuracy: 0.1292 - val_loss: 2.4723 - val_accuracy: 0.1239\n",
      "Epoch 203/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4300 - accuracy: 0.1274 - val_loss: 2.4720 - val_accuracy: 0.1239\n",
      "Epoch 204/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4321 - accuracy: 0.1274 - val_loss: 2.4720 - val_accuracy: 0.1239\n",
      "Epoch 205/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4271 - accuracy: 0.1274 - val_loss: 2.4624 - val_accuracy: 0.1239\n",
      "Epoch 206/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4263 - accuracy: 0.1310 - val_loss: 2.4650 - val_accuracy: 0.1239\n",
      "Epoch 207/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4254 - accuracy: 0.1257 - val_loss: 2.4642 - val_accuracy: 0.1239\n",
      "Epoch 208/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4319 - accuracy: 0.1221 - val_loss: 2.4602 - val_accuracy: 0.1239\n",
      "Epoch 209/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4259 - accuracy: 0.1274 - val_loss: 2.4603 - val_accuracy: 0.1239\n",
      "Epoch 210/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4207 - accuracy: 0.1274 - val_loss: 2.4701 - val_accuracy: 0.1239\n",
      "Epoch 211/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4216 - accuracy: 0.1292 - val_loss: 2.4696 - val_accuracy: 0.1239\n",
      "Epoch 212/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4276 - accuracy: 0.1292 - val_loss: 2.4697 - val_accuracy: 0.1239\n",
      "Epoch 213/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4222 - accuracy: 0.1274 - val_loss: 2.4739 - val_accuracy: 0.1327\n",
      "Epoch 214/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4166 - accuracy: 0.1257 - val_loss: 2.4678 - val_accuracy: 0.1239\n",
      "Epoch 215/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4244 - accuracy: 0.1239 - val_loss: 2.4706 - val_accuracy: 0.1239\n",
      "Epoch 216/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4247 - accuracy: 0.1204 - val_loss: 2.4696 - val_accuracy: 0.1239\n",
      "Epoch 217/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4241 - accuracy: 0.1327 - val_loss: 2.4777 - val_accuracy: 0.1239\n",
      "Epoch 218/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4130 - accuracy: 0.1327 - val_loss: 2.4712 - val_accuracy: 0.1239\n",
      "Epoch 219/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4115 - accuracy: 0.1292 - val_loss: 2.4763 - val_accuracy: 0.1239\n",
      "Epoch 220/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4166 - accuracy: 0.1292 - val_loss: 2.4619 - val_accuracy: 0.1239\n",
      "Epoch 221/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4159 - accuracy: 0.1292 - val_loss: 2.4654 - val_accuracy: 0.1239\n",
      "Epoch 222/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4224 - accuracy: 0.1239 - val_loss: 2.4694 - val_accuracy: 0.1239\n",
      "Epoch 223/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4172 - accuracy: 0.1310 - val_loss: 2.4885 - val_accuracy: 0.1239\n",
      "Epoch 224/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4160 - accuracy: 0.1257 - val_loss: 2.4530 - val_accuracy: 0.1239\n",
      "Epoch 225/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4141 - accuracy: 0.1310 - val_loss: 2.4528 - val_accuracy: 0.1239\n",
      "Epoch 226/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4193 - accuracy: 0.1310 - val_loss: 2.4526 - val_accuracy: 0.1239\n",
      "Epoch 227/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4063 - accuracy: 0.1292 - val_loss: 2.4649 - val_accuracy: 0.1239\n",
      "Epoch 228/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4110 - accuracy: 0.1257 - val_loss: 2.4578 - val_accuracy: 0.1239\n",
      "Epoch 229/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4038 - accuracy: 0.1345 - val_loss: 2.4719 - val_accuracy: 0.1239\n",
      "Epoch 230/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4099 - accuracy: 0.1327 - val_loss: 2.4649 - val_accuracy: 0.1327\n",
      "Epoch 231/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3994 - accuracy: 0.1327 - val_loss: 2.4819 - val_accuracy: 0.1239\n",
      "Epoch 232/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4032 - accuracy: 0.1327 - val_loss: 2.4730 - val_accuracy: 0.1239\n",
      "Epoch 233/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4017 - accuracy: 0.1345 - val_loss: 2.4747 - val_accuracy: 0.1239\n",
      "Epoch 234/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4004 - accuracy: 0.1327 - val_loss: 2.4667 - val_accuracy: 0.1239\n",
      "Epoch 235/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4031 - accuracy: 0.1310 - val_loss: 2.4744 - val_accuracy: 0.1239\n",
      "Epoch 236/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3988 - accuracy: 0.1363 - val_loss: 2.4574 - val_accuracy: 0.1239\n",
      "Epoch 237/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3970 - accuracy: 0.1345 - val_loss: 2.4575 - val_accuracy: 0.1239\n",
      "Epoch 238/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3950 - accuracy: 0.1310 - val_loss: 2.4678 - val_accuracy: 0.1239\n",
      "Epoch 239/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4043 - accuracy: 0.1292 - val_loss: 2.4517 - val_accuracy: 0.1239\n",
      "Epoch 240/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3911 - accuracy: 0.1363 - val_loss: 2.4604 - val_accuracy: 0.1239\n",
      "Epoch 241/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3919 - accuracy: 0.1381 - val_loss: 2.4691 - val_accuracy: 0.1239\n",
      "Epoch 242/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3894 - accuracy: 0.1310 - val_loss: 2.4689 - val_accuracy: 0.1239\n",
      "Epoch 243/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3968 - accuracy: 0.1292 - val_loss: 2.4602 - val_accuracy: 0.1239\n",
      "Epoch 244/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4061 - accuracy: 0.1292 - val_loss: 2.4635 - val_accuracy: 0.1239\n",
      "Epoch 245/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3831 - accuracy: 0.1345 - val_loss: 2.4668 - val_accuracy: 0.1239\n",
      "Epoch 246/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3878 - accuracy: 0.1345 - val_loss: 2.4536 - val_accuracy: 0.1239\n",
      "Epoch 247/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4050 - accuracy: 0.1292 - val_loss: 2.4546 - val_accuracy: 0.1239\n",
      "Epoch 248/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3939 - accuracy: 0.1310 - val_loss: 2.4560 - val_accuracy: 0.1239\n",
      "Epoch 249/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3844 - accuracy: 0.1274 - val_loss: 2.4675 - val_accuracy: 0.1239\n",
      "Epoch 250/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3849 - accuracy: 0.1327 - val_loss: 2.4688 - val_accuracy: 0.1327\n",
      "Epoch 251/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3781 - accuracy: 0.1363 - val_loss: 2.4697 - val_accuracy: 0.1239\n",
      "Epoch 252/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3922 - accuracy: 0.1327 - val_loss: 2.4565 - val_accuracy: 0.1239\n",
      "Epoch 253/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3819 - accuracy: 0.1310 - val_loss: 2.4626 - val_accuracy: 0.1327\n",
      "Epoch 254/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3891 - accuracy: 0.1292 - val_loss: 2.4611 - val_accuracy: 0.1239\n",
      "Epoch 255/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3835 - accuracy: 0.1327 - val_loss: 2.4559 - val_accuracy: 0.1239\n",
      "Epoch 256/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3824 - accuracy: 0.1345 - val_loss: 2.4644 - val_accuracy: 0.1239\n",
      "Epoch 257/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3903 - accuracy: 0.1292 - val_loss: 2.4550 - val_accuracy: 0.1327\n",
      "Epoch 258/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3820 - accuracy: 0.1257 - val_loss: 2.4583 - val_accuracy: 0.1239\n",
      "Epoch 259/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3791 - accuracy: 0.1327 - val_loss: 2.4628 - val_accuracy: 0.1239\n",
      "Epoch 260/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3781 - accuracy: 0.1345 - val_loss: 2.4549 - val_accuracy: 0.1239\n",
      "Epoch 261/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3824 - accuracy: 0.1363 - val_loss: 2.4583 - val_accuracy: 0.1327\n",
      "Epoch 262/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3754 - accuracy: 0.1327 - val_loss: 2.4610 - val_accuracy: 0.1327\n",
      "Epoch 263/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3825 - accuracy: 0.1327 - val_loss: 2.4571 - val_accuracy: 0.1327\n",
      "Epoch 264/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3735 - accuracy: 0.1310 - val_loss: 2.4561 - val_accuracy: 0.1327\n",
      "Epoch 265/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3768 - accuracy: 0.1327 - val_loss: 2.4639 - val_accuracy: 0.1239\n",
      "Epoch 266/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3718 - accuracy: 0.1363 - val_loss: 2.4631 - val_accuracy: 0.1327\n",
      "Epoch 267/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3774 - accuracy: 0.1327 - val_loss: 2.4662 - val_accuracy: 0.1327\n",
      "Epoch 268/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3668 - accuracy: 0.1381 - val_loss: 2.4574 - val_accuracy: 0.1327\n",
      "Epoch 269/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.4082 - accuracy: 0.1416 - val_loss: 2.4715 - val_accuracy: 0.1239\n",
      "Epoch 270/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3743 - accuracy: 0.1274 - val_loss: 2.4717 - val_accuracy: 0.1239\n",
      "Epoch 271/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3779 - accuracy: 0.1327 - val_loss: 2.4494 - val_accuracy: 0.1327\n",
      "Epoch 272/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3827 - accuracy: 0.1310 - val_loss: 2.4474 - val_accuracy: 0.1327\n",
      "Epoch 273/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3798 - accuracy: 0.1292 - val_loss: 2.4414 - val_accuracy: 0.1327\n",
      "Epoch 274/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3722 - accuracy: 0.1345 - val_loss: 2.4473 - val_accuracy: 0.1327\n",
      "Epoch 275/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3738 - accuracy: 0.1363 - val_loss: 2.4465 - val_accuracy: 0.1327\n",
      "Epoch 276/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3826 - accuracy: 0.1327 - val_loss: 2.4392 - val_accuracy: 0.1327\n",
      "Epoch 277/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3658 - accuracy: 0.1434 - val_loss: 2.4465 - val_accuracy: 0.1327\n",
      "Epoch 278/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.1398 - val_loss: 2.4473 - val_accuracy: 0.1327\n",
      "Epoch 279/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3673 - accuracy: 0.1345 - val_loss: 2.4415 - val_accuracy: 0.1327\n",
      "Epoch 280/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3657 - accuracy: 0.1381 - val_loss: 2.4403 - val_accuracy: 0.1327\n",
      "Epoch 281/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3653 - accuracy: 0.1416 - val_loss: 2.4501 - val_accuracy: 0.1327\n",
      "Epoch 282/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3593 - accuracy: 0.1416 - val_loss: 2.4445 - val_accuracy: 0.1327\n",
      "Epoch 283/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3649 - accuracy: 0.1381 - val_loss: 2.4444 - val_accuracy: 0.1327\n",
      "Epoch 284/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3627 - accuracy: 0.1434 - val_loss: 2.4481 - val_accuracy: 0.1327\n",
      "Epoch 285/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3592 - accuracy: 0.1381 - val_loss: 2.4503 - val_accuracy: 0.1327\n",
      "Epoch 286/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3636 - accuracy: 0.1416 - val_loss: 2.4469 - val_accuracy: 0.1327\n",
      "Epoch 287/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3538 - accuracy: 0.1469 - val_loss: 2.4564 - val_accuracy: 0.1327\n",
      "Epoch 288/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3580 - accuracy: 0.1398 - val_loss: 2.4543 - val_accuracy: 0.1327\n",
      "Epoch 289/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3582 - accuracy: 0.1310 - val_loss: 2.4433 - val_accuracy: 0.1327\n",
      "Epoch 290/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3528 - accuracy: 0.1416 - val_loss: 2.4494 - val_accuracy: 0.1327\n",
      "Epoch 291/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3515 - accuracy: 0.1451 - val_loss: 2.4548 - val_accuracy: 0.1327\n",
      "Epoch 292/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3564 - accuracy: 0.1434 - val_loss: 2.4340 - val_accuracy: 0.1327\n",
      "Epoch 293/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3600 - accuracy: 0.1416 - val_loss: 2.4333 - val_accuracy: 0.1327\n",
      "Epoch 294/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3621 - accuracy: 0.1434 - val_loss: 2.4569 - val_accuracy: 0.1327\n",
      "Epoch 295/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3597 - accuracy: 0.1434 - val_loss: 2.4627 - val_accuracy: 0.1327\n",
      "Epoch 296/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3552 - accuracy: 0.1434 - val_loss: 2.4341 - val_accuracy: 0.1327\n",
      "Epoch 297/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3522 - accuracy: 0.1451 - val_loss: 2.4421 - val_accuracy: 0.1327\n",
      "Epoch 298/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3690 - accuracy: 0.1381 - val_loss: 2.4490 - val_accuracy: 0.1327\n",
      "Epoch 299/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3497 - accuracy: 0.1416 - val_loss: 2.4579 - val_accuracy: 0.1327\n",
      "Epoch 300/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3487 - accuracy: 0.1434 - val_loss: 2.4584 - val_accuracy: 0.1327\n",
      "Epoch 301/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3559 - accuracy: 0.1416 - val_loss: 2.4579 - val_accuracy: 0.1327\n",
      "Epoch 302/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3504 - accuracy: 0.1451 - val_loss: 2.4599 - val_accuracy: 0.1327\n",
      "Epoch 303/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3417 - accuracy: 0.1434 - val_loss: 2.4584 - val_accuracy: 0.1327\n",
      "Epoch 304/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3537 - accuracy: 0.1434 - val_loss: 2.4614 - val_accuracy: 0.1327\n",
      "Epoch 305/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3432 - accuracy: 0.1451 - val_loss: 2.4551 - val_accuracy: 0.1327\n",
      "Epoch 306/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3389 - accuracy: 0.1469 - val_loss: 2.4587 - val_accuracy: 0.1327\n",
      "Epoch 307/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3720 - accuracy: 0.1381 - val_loss: 2.4607 - val_accuracy: 0.1327\n",
      "Epoch 308/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3385 - accuracy: 0.1434 - val_loss: 2.4537 - val_accuracy: 0.1327\n",
      "Epoch 309/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3411 - accuracy: 0.1451 - val_loss: 2.4512 - val_accuracy: 0.1327\n",
      "Epoch 310/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3430 - accuracy: 0.1416 - val_loss: 2.4444 - val_accuracy: 0.1327\n",
      "Epoch 311/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3442 - accuracy: 0.1434 - val_loss: 2.4529 - val_accuracy: 0.1327\n",
      "Epoch 312/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3448 - accuracy: 0.1416 - val_loss: 2.4462 - val_accuracy: 0.1327\n",
      "Epoch 313/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3486 - accuracy: 0.1434 - val_loss: 2.4231 - val_accuracy: 0.1327\n",
      "Epoch 314/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3440 - accuracy: 0.1451 - val_loss: 2.4414 - val_accuracy: 0.1327\n",
      "Epoch 315/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3400 - accuracy: 0.1487 - val_loss: 2.4542 - val_accuracy: 0.1327\n",
      "Epoch 316/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3373 - accuracy: 0.1451 - val_loss: 2.4548 - val_accuracy: 0.1327\n",
      "Epoch 317/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3373 - accuracy: 0.1434 - val_loss: 2.4462 - val_accuracy: 0.1327\n",
      "Epoch 318/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3437 - accuracy: 0.1451 - val_loss: 2.4588 - val_accuracy: 0.1327\n",
      "Epoch 319/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3357 - accuracy: 0.1416 - val_loss: 2.4436 - val_accuracy: 0.1327\n",
      "Epoch 320/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3431 - accuracy: 0.1416 - val_loss: 2.4449 - val_accuracy: 0.1327\n",
      "Epoch 321/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3318 - accuracy: 0.1451 - val_loss: 2.4643 - val_accuracy: 0.1327\n",
      "Epoch 322/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3361 - accuracy: 0.1451 - val_loss: 2.4644 - val_accuracy: 0.1327\n",
      "Epoch 323/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3335 - accuracy: 0.1504 - val_loss: 2.4622 - val_accuracy: 0.1327\n",
      "Epoch 324/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3376 - accuracy: 0.1504 - val_loss: 2.4657 - val_accuracy: 0.1327\n",
      "Epoch 325/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3381 - accuracy: 0.1487 - val_loss: 2.4529 - val_accuracy: 0.1327\n",
      "Epoch 326/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3314 - accuracy: 0.1434 - val_loss: 2.4539 - val_accuracy: 0.1327\n",
      "Epoch 327/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3352 - accuracy: 0.1381 - val_loss: 2.4535 - val_accuracy: 0.1327\n",
      "Epoch 328/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3374 - accuracy: 0.1398 - val_loss: 2.4389 - val_accuracy: 0.1327\n",
      "Epoch 329/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3266 - accuracy: 0.1487 - val_loss: 2.4479 - val_accuracy: 0.1327\n",
      "Epoch 330/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3209 - accuracy: 0.1469 - val_loss: 2.4614 - val_accuracy: 0.1327\n",
      "Epoch 331/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3248 - accuracy: 0.1487 - val_loss: 2.4462 - val_accuracy: 0.1327\n",
      "Epoch 332/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3234 - accuracy: 0.1469 - val_loss: 2.4421 - val_accuracy: 0.1327\n",
      "Epoch 333/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3243 - accuracy: 0.1487 - val_loss: 2.4439 - val_accuracy: 0.1327\n",
      "Epoch 334/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3266 - accuracy: 0.1434 - val_loss: 2.4424 - val_accuracy: 0.1327\n",
      "Epoch 335/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3228 - accuracy: 0.1451 - val_loss: 2.4473 - val_accuracy: 0.1327\n",
      "Epoch 336/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3259 - accuracy: 0.1451 - val_loss: 2.4588 - val_accuracy: 0.1327\n",
      "Epoch 337/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3210 - accuracy: 0.1469 - val_loss: 2.4416 - val_accuracy: 0.1327\n",
      "Epoch 338/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3291 - accuracy: 0.1504 - val_loss: 2.4528 - val_accuracy: 0.1327\n",
      "Epoch 339/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3292 - accuracy: 0.1416 - val_loss: 2.4520 - val_accuracy: 0.1327\n",
      "Epoch 340/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3319 - accuracy: 0.1416 - val_loss: 2.4626 - val_accuracy: 0.1327\n",
      "Epoch 341/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3303 - accuracy: 0.1434 - val_loss: 2.4454 - val_accuracy: 0.1327\n",
      "Epoch 342/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3195 - accuracy: 0.1522 - val_loss: 2.4549 - val_accuracy: 0.1327\n",
      "Epoch 343/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3196 - accuracy: 0.1434 - val_loss: 2.4624 - val_accuracy: 0.1327\n",
      "Epoch 344/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3171 - accuracy: 0.1487 - val_loss: 2.4543 - val_accuracy: 0.1327\n",
      "Epoch 345/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.1434 - val_loss: 2.4513 - val_accuracy: 0.1327\n",
      "Epoch 346/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3460 - accuracy: 0.1451 - val_loss: 2.4558 - val_accuracy: 0.1327\n",
      "Epoch 347/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3262 - accuracy: 0.1416 - val_loss: 2.4470 - val_accuracy: 0.1327\n",
      "Epoch 348/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3283 - accuracy: 0.1434 - val_loss: 2.4720 - val_accuracy: 0.1327\n",
      "Epoch 349/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3345 - accuracy: 0.1487 - val_loss: 2.4414 - val_accuracy: 0.1327\n",
      "Epoch 350/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3286 - accuracy: 0.1434 - val_loss: 2.4415 - val_accuracy: 0.1327\n",
      "Epoch 351/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3183 - accuracy: 0.1558 - val_loss: 2.4536 - val_accuracy: 0.1327\n",
      "Epoch 352/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3186 - accuracy: 0.1451 - val_loss: 2.4664 - val_accuracy: 0.1327\n",
      "Epoch 353/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3156 - accuracy: 0.1451 - val_loss: 2.4534 - val_accuracy: 0.1327\n",
      "Epoch 354/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3195 - accuracy: 0.1540 - val_loss: 2.4516 - val_accuracy: 0.1327\n",
      "Epoch 355/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3245 - accuracy: 0.1487 - val_loss: 2.4566 - val_accuracy: 0.1327\n",
      "Epoch 356/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3203 - accuracy: 0.1487 - val_loss: 2.4458 - val_accuracy: 0.1327\n",
      "Epoch 357/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3237 - accuracy: 0.1451 - val_loss: 2.4627 - val_accuracy: 0.1327\n",
      "Epoch 358/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3118 - accuracy: 0.1540 - val_loss: 2.4432 - val_accuracy: 0.1327\n",
      "Epoch 359/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3116 - accuracy: 0.1504 - val_loss: 2.4478 - val_accuracy: 0.1327\n",
      "Epoch 360/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3082 - accuracy: 0.1522 - val_loss: 2.4526 - val_accuracy: 0.1327\n",
      "Epoch 361/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3213 - accuracy: 0.1434 - val_loss: 2.4474 - val_accuracy: 0.1327\n",
      "Epoch 362/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3150 - accuracy: 0.1469 - val_loss: 2.4531 - val_accuracy: 0.1327\n",
      "Epoch 363/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3107 - accuracy: 0.1504 - val_loss: 2.4491 - val_accuracy: 0.1327\n",
      "Epoch 364/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3062 - accuracy: 0.1593 - val_loss: 2.4528 - val_accuracy: 0.1327\n",
      "Epoch 365/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3092 - accuracy: 0.1522 - val_loss: 2.4547 - val_accuracy: 0.1327\n",
      "Epoch 366/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3077 - accuracy: 0.1522 - val_loss: 2.4504 - val_accuracy: 0.1327\n",
      "Epoch 367/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3012 - accuracy: 0.1504 - val_loss: 2.4473 - val_accuracy: 0.1327\n",
      "Epoch 368/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3030 - accuracy: 0.1575 - val_loss: 2.4450 - val_accuracy: 0.1327\n",
      "Epoch 369/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2982 - accuracy: 0.1540 - val_loss: 2.4437 - val_accuracy: 0.1327\n",
      "Epoch 370/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3032 - accuracy: 0.1628 - val_loss: 2.4516 - val_accuracy: 0.1327\n",
      "Epoch 371/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2976 - accuracy: 0.1558 - val_loss: 2.4541 - val_accuracy: 0.1327\n",
      "Epoch 372/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3082 - accuracy: 0.1504 - val_loss: 2.4474 - val_accuracy: 0.1416\n",
      "Epoch 373/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3046 - accuracy: 0.1628 - val_loss: 2.4427 - val_accuracy: 0.1416\n",
      "Epoch 374/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3024 - accuracy: 0.1575 - val_loss: 2.4342 - val_accuracy: 0.1416\n",
      "Epoch 375/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2930 - accuracy: 0.1699 - val_loss: 2.4315 - val_accuracy: 0.1416\n",
      "Epoch 376/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3002 - accuracy: 0.1575 - val_loss: 2.4517 - val_accuracy: 0.1416\n",
      "Epoch 377/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3093 - accuracy: 0.1558 - val_loss: 2.4387 - val_accuracy: 0.1416\n",
      "Epoch 378/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2938 - accuracy: 0.1699 - val_loss: 2.4287 - val_accuracy: 0.1327\n",
      "Epoch 379/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3046 - accuracy: 0.1575 - val_loss: 2.4230 - val_accuracy: 0.1416\n",
      "Epoch 380/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2956 - accuracy: 0.1735 - val_loss: 2.4317 - val_accuracy: 0.1504\n",
      "Epoch 381/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3123 - accuracy: 0.1611 - val_loss: 2.4475 - val_accuracy: 0.1504\n",
      "Epoch 382/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2901 - accuracy: 0.1646 - val_loss: 2.4758 - val_accuracy: 0.1327\n",
      "Epoch 383/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2956 - accuracy: 0.1681 - val_loss: 2.4772 - val_accuracy: 0.1416\n",
      "Epoch 384/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2985 - accuracy: 0.1593 - val_loss: 2.4648 - val_accuracy: 0.1416\n",
      "Epoch 385/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2944 - accuracy: 0.1681 - val_loss: 2.4655 - val_accuracy: 0.1416\n",
      "Epoch 386/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2917 - accuracy: 0.1593 - val_loss: 2.4781 - val_accuracy: 0.1416\n",
      "Epoch 387/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2852 - accuracy: 0.1593 - val_loss: 2.4772 - val_accuracy: 0.1416\n",
      "Epoch 388/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2909 - accuracy: 0.1788 - val_loss: 2.4345 - val_accuracy: 0.1327\n",
      "Epoch 389/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2900 - accuracy: 0.1681 - val_loss: 2.4544 - val_accuracy: 0.1416\n",
      "Epoch 390/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2900 - accuracy: 0.1699 - val_loss: 2.4608 - val_accuracy: 0.1504\n",
      "Epoch 391/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2865 - accuracy: 0.1681 - val_loss: 2.4622 - val_accuracy: 0.1504\n",
      "Epoch 392/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2649 - accuracy: 0.1858 - val_loss: 2.4608 - val_accuracy: 0.1327\n",
      "Epoch 393/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2787 - accuracy: 0.1717 - val_loss: 2.4601 - val_accuracy: 0.1504\n",
      "Epoch 394/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2870 - accuracy: 0.1735 - val_loss: 2.4552 - val_accuracy: 0.1504\n",
      "Epoch 395/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2803 - accuracy: 0.1699 - val_loss: 2.4729 - val_accuracy: 0.1416\n",
      "Epoch 396/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2842 - accuracy: 0.1646 - val_loss: 2.4659 - val_accuracy: 0.1504\n",
      "Epoch 397/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2811 - accuracy: 0.1681 - val_loss: 2.4424 - val_accuracy: 0.1416\n",
      "Epoch 398/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2798 - accuracy: 0.1681 - val_loss: 2.4206 - val_accuracy: 0.1593\n",
      "Epoch 399/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2801 - accuracy: 0.1805 - val_loss: 2.4450 - val_accuracy: 0.1593\n",
      "Epoch 400/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2653 - accuracy: 0.1717 - val_loss: 2.4550 - val_accuracy: 0.1416\n",
      "Epoch 401/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2651 - accuracy: 0.1823 - val_loss: 2.4442 - val_accuracy: 0.1593\n",
      "Epoch 402/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2719 - accuracy: 0.1752 - val_loss: 2.4436 - val_accuracy: 0.1593\n",
      "Epoch 403/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2654 - accuracy: 0.1788 - val_loss: 2.4190 - val_accuracy: 0.1681\n",
      "Epoch 404/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2521 - accuracy: 0.1805 - val_loss: 2.4247 - val_accuracy: 0.1947\n",
      "Epoch 405/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2478 - accuracy: 0.1912 - val_loss: 2.4354 - val_accuracy: 0.1770\n",
      "Epoch 406/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2531 - accuracy: 0.1823 - val_loss: 2.4264 - val_accuracy: 0.1858\n",
      "Epoch 407/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2380 - accuracy: 0.1982 - val_loss: 2.4373 - val_accuracy: 0.1681\n",
      "Epoch 408/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2564 - accuracy: 0.1788 - val_loss: 2.4398 - val_accuracy: 0.1504\n",
      "Epoch 409/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2556 - accuracy: 0.1841 - val_loss: 2.4278 - val_accuracy: 0.1593\n",
      "Epoch 410/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2577 - accuracy: 0.1805 - val_loss: 2.4255 - val_accuracy: 0.1770\n",
      "Epoch 411/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2445 - accuracy: 0.1876 - val_loss: 2.4101 - val_accuracy: 0.1593\n",
      "Epoch 412/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2299 - accuracy: 0.1876 - val_loss: 2.4036 - val_accuracy: 0.1858\n",
      "Epoch 413/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2565 - accuracy: 0.1699 - val_loss: 2.4003 - val_accuracy: 0.1681\n",
      "Epoch 414/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2625 - accuracy: 0.1805 - val_loss: 2.4014 - val_accuracy: 0.1770\n",
      "Epoch 415/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2652 - accuracy: 0.1681 - val_loss: 2.4095 - val_accuracy: 0.1947\n",
      "Epoch 416/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2512 - accuracy: 0.1841 - val_loss: 2.4210 - val_accuracy: 0.1947\n",
      "Epoch 417/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2176 - accuracy: 0.1929 - val_loss: 2.4109 - val_accuracy: 0.1858\n",
      "Epoch 418/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2386 - accuracy: 0.2124 - val_loss: 2.3972 - val_accuracy: 0.2124\n",
      "Epoch 419/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2266 - accuracy: 0.1947 - val_loss: 2.4284 - val_accuracy: 0.1770\n",
      "Epoch 420/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2541 - accuracy: 0.1735 - val_loss: 2.4271 - val_accuracy: 0.1681\n",
      "Epoch 421/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2645 - accuracy: 0.1752 - val_loss: 2.4219 - val_accuracy: 0.1681\n",
      "Epoch 422/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2510 - accuracy: 0.1752 - val_loss: 2.4193 - val_accuracy: 0.1947\n",
      "Epoch 423/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2551 - accuracy: 0.1681 - val_loss: 2.4120 - val_accuracy: 0.1681\n",
      "Epoch 424/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2384 - accuracy: 0.1841 - val_loss: 2.4090 - val_accuracy: 0.1770\n",
      "Epoch 425/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2495 - accuracy: 0.1752 - val_loss: 2.4076 - val_accuracy: 0.1858\n",
      "Epoch 426/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2497 - accuracy: 0.1717 - val_loss: 2.4037 - val_accuracy: 0.1858\n",
      "Epoch 427/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2352 - accuracy: 0.1912 - val_loss: 2.3996 - val_accuracy: 0.1947\n",
      "Epoch 428/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2432 - accuracy: 0.1912 - val_loss: 2.3883 - val_accuracy: 0.1947\n",
      "Epoch 429/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2576 - accuracy: 0.1823 - val_loss: 2.4028 - val_accuracy: 0.1947\n",
      "Epoch 430/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2308 - accuracy: 0.1929 - val_loss: 2.3922 - val_accuracy: 0.2035\n",
      "Epoch 431/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2264 - accuracy: 0.1929 - val_loss: 2.3941 - val_accuracy: 0.2035\n",
      "Epoch 432/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2450 - accuracy: 0.1699 - val_loss: 2.3859 - val_accuracy: 0.2035\n",
      "Epoch 433/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2262 - accuracy: 0.1947 - val_loss: 2.3779 - val_accuracy: 0.2124\n",
      "Epoch 434/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2277 - accuracy: 0.2000 - val_loss: 2.3807 - val_accuracy: 0.2035\n",
      "Epoch 435/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2451 - accuracy: 0.1805 - val_loss: 2.4027 - val_accuracy: 0.1947\n",
      "Epoch 436/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2423 - accuracy: 0.1735 - val_loss: 2.4088 - val_accuracy: 0.1858\n",
      "Epoch 437/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2415 - accuracy: 0.1841 - val_loss: 2.3941 - val_accuracy: 0.1947\n",
      "Epoch 438/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2354 - accuracy: 0.1912 - val_loss: 2.3900 - val_accuracy: 0.1947\n",
      "Epoch 439/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2468 - accuracy: 0.1699 - val_loss: 2.3975 - val_accuracy: 0.1947\n",
      "Epoch 440/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2276 - accuracy: 0.1788 - val_loss: 2.3768 - val_accuracy: 0.1770\n",
      "Epoch 441/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2352 - accuracy: 0.1752 - val_loss: 2.3588 - val_accuracy: 0.1770\n",
      "Epoch 442/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2216 - accuracy: 0.1947 - val_loss: 2.3502 - val_accuracy: 0.2124\n",
      "Epoch 443/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2379 - accuracy: 0.1823 - val_loss: 2.3529 - val_accuracy: 0.2124\n",
      "Epoch 444/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2104 - accuracy: 0.1876 - val_loss: 2.3145 - val_accuracy: 0.2124\n",
      "Epoch 445/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2149 - accuracy: 0.1912 - val_loss: 2.3297 - val_accuracy: 0.2035\n",
      "Epoch 446/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2109 - accuracy: 0.2142 - val_loss: 2.3541 - val_accuracy: 0.1947\n",
      "Epoch 447/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2076 - accuracy: 0.2018 - val_loss: 2.3444 - val_accuracy: 0.2124\n",
      "Epoch 448/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1816 - accuracy: 0.2018 - val_loss: 2.3423 - val_accuracy: 0.2212\n",
      "Epoch 449/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1922 - accuracy: 0.2142 - val_loss: 2.3167 - val_accuracy: 0.2212\n",
      "Epoch 450/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1626 - accuracy: 0.2283 - val_loss: 2.2780 - val_accuracy: 0.2655\n",
      "Epoch 451/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1479 - accuracy: 0.2124 - val_loss: 2.2766 - val_accuracy: 0.2301\n",
      "Epoch 452/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1804 - accuracy: 0.2124 - val_loss: 2.3166 - val_accuracy: 0.2212\n",
      "Epoch 453/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1475 - accuracy: 0.2212 - val_loss: 2.2729 - val_accuracy: 0.2301\n",
      "Epoch 454/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1512 - accuracy: 0.2142 - val_loss: 2.2234 - val_accuracy: 0.2832\n",
      "Epoch 455/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1000 - accuracy: 0.2354 - val_loss: 2.1894 - val_accuracy: 0.2832\n",
      "Epoch 456/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1139 - accuracy: 0.2513 - val_loss: 2.1867 - val_accuracy: 0.2124\n",
      "Epoch 457/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1029 - accuracy: 0.2407 - val_loss: 2.1497 - val_accuracy: 0.2566\n",
      "Epoch 458/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1508 - accuracy: 0.2336 - val_loss: 2.2650 - val_accuracy: 0.2212\n",
      "Epoch 459/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1196 - accuracy: 0.2496 - val_loss: 2.1772 - val_accuracy: 0.2920\n",
      "Epoch 460/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0696 - accuracy: 0.2584 - val_loss: 2.1590 - val_accuracy: 0.3186\n",
      "Epoch 461/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0650 - accuracy: 0.2637 - val_loss: 2.1568 - val_accuracy: 0.2832\n",
      "Epoch 462/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0756 - accuracy: 0.2442 - val_loss: 2.1037 - val_accuracy: 0.2832\n",
      "Epoch 463/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0453 - accuracy: 0.2566 - val_loss: 2.0784 - val_accuracy: 0.3805\n",
      "Epoch 464/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9905 - accuracy: 0.2956 - val_loss: 2.0572 - val_accuracy: 0.3363\n",
      "Epoch 465/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0134 - accuracy: 0.2832 - val_loss: 2.0512 - val_accuracy: 0.3274\n",
      "Epoch 466/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0377 - accuracy: 0.2832 - val_loss: 2.0408 - val_accuracy: 0.3009\n",
      "Epoch 467/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9696 - accuracy: 0.2761 - val_loss: 2.0042 - val_accuracy: 0.3451\n",
      "Epoch 468/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0104 - accuracy: 0.3080 - val_loss: 2.0338 - val_accuracy: 0.3274\n",
      "Epoch 469/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9781 - accuracy: 0.2903 - val_loss: 1.9738 - val_accuracy: 0.3540\n",
      "Epoch 470/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9758 - accuracy: 0.2708 - val_loss: 1.9737 - val_accuracy: 0.3628\n",
      "Epoch 471/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9660 - accuracy: 0.2938 - val_loss: 1.9453 - val_accuracy: 0.3717\n",
      "Epoch 472/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9004 - accuracy: 0.2867 - val_loss: 1.9218 - val_accuracy: 0.4071\n",
      "Epoch 473/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8865 - accuracy: 0.3221 - val_loss: 1.9180 - val_accuracy: 0.3982\n",
      "Epoch 474/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9027 - accuracy: 0.3133 - val_loss: 1.9285 - val_accuracy: 0.3982\n",
      "Epoch 475/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8786 - accuracy: 0.3327 - val_loss: 1.9882 - val_accuracy: 0.3451\n",
      "Epoch 476/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9256 - accuracy: 0.3115 - val_loss: 1.9259 - val_accuracy: 0.4248\n",
      "Epoch 477/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8749 - accuracy: 0.3274 - val_loss: 1.8861 - val_accuracy: 0.4071\n",
      "Epoch 478/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8818 - accuracy: 0.3204 - val_loss: 1.8941 - val_accuracy: 0.3805\n",
      "Epoch 479/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8646 - accuracy: 0.3434 - val_loss: 1.8847 - val_accuracy: 0.3805\n",
      "Epoch 480/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8718 - accuracy: 0.3204 - val_loss: 1.9066 - val_accuracy: 0.3540\n",
      "Epoch 481/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8925 - accuracy: 0.3257 - val_loss: 1.8950 - val_accuracy: 0.3894\n",
      "Epoch 482/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8969 - accuracy: 0.3221 - val_loss: 1.9125 - val_accuracy: 0.3805\n",
      "Epoch 483/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8913 - accuracy: 0.3239 - val_loss: 1.9114 - val_accuracy: 0.3717\n",
      "Epoch 484/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8261 - accuracy: 0.3363 - val_loss: 1.8710 - val_accuracy: 0.4159\n",
      "Epoch 485/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8301 - accuracy: 0.3487 - val_loss: 1.8558 - val_accuracy: 0.3982\n",
      "Epoch 486/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8168 - accuracy: 0.3504 - val_loss: 1.8484 - val_accuracy: 0.4159\n",
      "Epoch 487/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8195 - accuracy: 0.3451 - val_loss: 1.8843 - val_accuracy: 0.4248\n",
      "Epoch 488/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7987 - accuracy: 0.3575 - val_loss: 1.8745 - val_accuracy: 0.4159\n",
      "Epoch 489/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.3558 - val_loss: 1.8729 - val_accuracy: 0.4248\n",
      "Epoch 490/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8036 - accuracy: 0.3646 - val_loss: 1.8361 - val_accuracy: 0.3894\n",
      "Epoch 491/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7758 - accuracy: 0.3664 - val_loss: 1.8422 - val_accuracy: 0.4425\n",
      "Epoch 492/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7871 - accuracy: 0.3646 - val_loss: 1.8530 - val_accuracy: 0.3982\n",
      "Epoch 493/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8012 - accuracy: 0.3805 - val_loss: 1.8293 - val_accuracy: 0.3982\n",
      "Epoch 494/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7867 - accuracy: 0.3575 - val_loss: 1.8211 - val_accuracy: 0.4071\n",
      "Epoch 495/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7739 - accuracy: 0.3912 - val_loss: 1.8108 - val_accuracy: 0.4159\n",
      "Epoch 496/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7732 - accuracy: 0.3805 - val_loss: 1.8288 - val_accuracy: 0.4071\n",
      "Epoch 497/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7637 - accuracy: 0.3664 - val_loss: 1.8711 - val_accuracy: 0.3628\n",
      "Epoch 498/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7608 - accuracy: 0.3752 - val_loss: 1.8271 - val_accuracy: 0.3894\n",
      "Epoch 499/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7652 - accuracy: 0.3823 - val_loss: 1.7877 - val_accuracy: 0.4248\n",
      "Epoch 500/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6937 - accuracy: 0.3982 - val_loss: 1.8050 - val_accuracy: 0.4159\n",
      "Epoch 501/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7439 - accuracy: 0.4053 - val_loss: 1.7754 - val_accuracy: 0.4336\n",
      "Epoch 502/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7228 - accuracy: 0.4053 - val_loss: 1.7850 - val_accuracy: 0.4513\n",
      "Epoch 503/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7545 - accuracy: 0.3699 - val_loss: 1.7813 - val_accuracy: 0.4425\n",
      "Epoch 504/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7177 - accuracy: 0.3912 - val_loss: 1.7507 - val_accuracy: 0.4248\n",
      "Epoch 505/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7612 - accuracy: 0.3646 - val_loss: 1.8207 - val_accuracy: 0.4248\n",
      "Epoch 506/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7629 - accuracy: 0.3770 - val_loss: 1.7889 - val_accuracy: 0.4071\n",
      "Epoch 507/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7221 - accuracy: 0.3929 - val_loss: 1.7502 - val_accuracy: 0.4159\n",
      "Epoch 508/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7565 - accuracy: 0.3681 - val_loss: 1.7705 - val_accuracy: 0.4336\n",
      "Epoch 509/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7098 - accuracy: 0.4124 - val_loss: 1.7529 - val_accuracy: 0.4248\n",
      "Epoch 510/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7185 - accuracy: 0.3876 - val_loss: 1.7626 - val_accuracy: 0.4336\n",
      "Epoch 511/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7647 - accuracy: 0.3805 - val_loss: 1.7785 - val_accuracy: 0.3717\n",
      "Epoch 512/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6980 - accuracy: 0.3894 - val_loss: 1.7240 - val_accuracy: 0.4602\n",
      "Epoch 513/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6710 - accuracy: 0.4159 - val_loss: 1.7528 - val_accuracy: 0.4248\n",
      "Epoch 514/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6838 - accuracy: 0.4301 - val_loss: 1.7705 - val_accuracy: 0.4513\n",
      "Epoch 515/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6834 - accuracy: 0.3947 - val_loss: 1.7712 - val_accuracy: 0.4336\n",
      "Epoch 516/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6743 - accuracy: 0.4248 - val_loss: 1.7591 - val_accuracy: 0.3894\n",
      "Epoch 517/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6787 - accuracy: 0.4053 - val_loss: 1.7324 - val_accuracy: 0.3982\n",
      "Epoch 518/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6741 - accuracy: 0.4283 - val_loss: 1.7302 - val_accuracy: 0.4425\n",
      "Epoch 519/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6867 - accuracy: 0.3947 - val_loss: 1.7681 - val_accuracy: 0.4602\n",
      "Epoch 520/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6836 - accuracy: 0.4230 - val_loss: 1.6884 - val_accuracy: 0.4425\n",
      "Epoch 521/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6279 - accuracy: 0.4195 - val_loss: 1.7011 - val_accuracy: 0.4779\n",
      "Epoch 522/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6293 - accuracy: 0.4336 - val_loss: 1.6985 - val_accuracy: 0.4248\n",
      "Epoch 523/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6293 - accuracy: 0.4230 - val_loss: 1.6957 - val_accuracy: 0.4602\n",
      "Epoch 524/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6706 - accuracy: 0.4336 - val_loss: 1.7118 - val_accuracy: 0.4867\n",
      "Epoch 525/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6177 - accuracy: 0.4212 - val_loss: 1.6494 - val_accuracy: 0.4779\n",
      "Epoch 526/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6010 - accuracy: 0.4354 - val_loss: 1.6639 - val_accuracy: 0.3982\n",
      "Epoch 527/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5945 - accuracy: 0.4336 - val_loss: 1.6586 - val_accuracy: 0.4690\n",
      "Epoch 528/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6040 - accuracy: 0.4372 - val_loss: 1.6525 - val_accuracy: 0.4425\n",
      "Epoch 529/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6560 - accuracy: 0.4124 - val_loss: 1.7373 - val_accuracy: 0.3894\n",
      "Epoch 530/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6432 - accuracy: 0.4106 - val_loss: 1.6740 - val_accuracy: 0.4690\n",
      "Epoch 531/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5647 - accuracy: 0.4531 - val_loss: 1.6745 - val_accuracy: 0.4425\n",
      "Epoch 532/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5885 - accuracy: 0.4460 - val_loss: 1.7016 - val_accuracy: 0.4602\n",
      "Epoch 533/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6214 - accuracy: 0.4088 - val_loss: 1.6458 - val_accuracy: 0.4956\n",
      "Epoch 534/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5681 - accuracy: 0.4513 - val_loss: 1.6711 - val_accuracy: 0.4159\n",
      "Epoch 535/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6283 - accuracy: 0.4319 - val_loss: 1.6384 - val_accuracy: 0.5221\n",
      "Epoch 536/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5726 - accuracy: 0.4478 - val_loss: 1.6556 - val_accuracy: 0.4690\n",
      "Epoch 537/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5867 - accuracy: 0.4195 - val_loss: 1.6389 - val_accuracy: 0.4956\n",
      "Epoch 538/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5668 - accuracy: 0.4442 - val_loss: 1.6368 - val_accuracy: 0.4690\n",
      "Epoch 539/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5648 - accuracy: 0.4584 - val_loss: 1.6108 - val_accuracy: 0.4867\n",
      "Epoch 540/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5901 - accuracy: 0.4212 - val_loss: 1.6103 - val_accuracy: 0.4602\n",
      "Epoch 541/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5555 - accuracy: 0.4602 - val_loss: 1.6040 - val_accuracy: 0.4690\n",
      "Epoch 542/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5485 - accuracy: 0.4531 - val_loss: 1.6384 - val_accuracy: 0.4513\n",
      "Epoch 543/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5292 - accuracy: 0.4867 - val_loss: 1.6091 - val_accuracy: 0.4602\n",
      "Epoch 544/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5026 - accuracy: 0.4867 - val_loss: 1.6478 - val_accuracy: 0.4513\n",
      "Epoch 545/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5200 - accuracy: 0.4513 - val_loss: 1.5798 - val_accuracy: 0.4779\n",
      "Epoch 546/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5097 - accuracy: 0.4619 - val_loss: 1.6094 - val_accuracy: 0.5044\n",
      "Epoch 547/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5126 - accuracy: 0.4779 - val_loss: 1.5830 - val_accuracy: 0.4779\n",
      "Epoch 548/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4894 - accuracy: 0.4619 - val_loss: 1.6003 - val_accuracy: 0.4867\n",
      "Epoch 549/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4624 - accuracy: 0.4708 - val_loss: 1.5756 - val_accuracy: 0.4690\n",
      "Epoch 550/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4874 - accuracy: 0.4814 - val_loss: 1.5711 - val_accuracy: 0.5487\n",
      "Epoch 551/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4774 - accuracy: 0.4743 - val_loss: 1.5511 - val_accuracy: 0.5221\n",
      "Epoch 552/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5116 - accuracy: 0.4885 - val_loss: 1.6111 - val_accuracy: 0.4690\n",
      "Epoch 553/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5064 - accuracy: 0.4637 - val_loss: 1.6096 - val_accuracy: 0.4425\n",
      "Epoch 554/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5159 - accuracy: 0.4637 - val_loss: 1.5603 - val_accuracy: 0.4690\n",
      "Epoch 555/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4909 - accuracy: 0.4920 - val_loss: 1.5795 - val_accuracy: 0.5133\n",
      "Epoch 556/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4666 - accuracy: 0.4991 - val_loss: 1.5654 - val_accuracy: 0.4425\n",
      "Epoch 557/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4718 - accuracy: 0.4743 - val_loss: 1.5603 - val_accuracy: 0.4956\n",
      "Epoch 558/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4755 - accuracy: 0.5009 - val_loss: 1.5308 - val_accuracy: 0.4779\n",
      "Epoch 559/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4784 - accuracy: 0.4850 - val_loss: 1.5578 - val_accuracy: 0.5221\n",
      "Epoch 560/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5127 - accuracy: 0.4619 - val_loss: 1.5414 - val_accuracy: 0.5133\n",
      "Epoch 561/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4615 - accuracy: 0.4867 - val_loss: 1.5170 - val_accuracy: 0.4956\n",
      "Epoch 562/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5007 - accuracy: 0.4584 - val_loss: 1.5295 - val_accuracy: 0.4779\n",
      "Epoch 563/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4338 - accuracy: 0.4885 - val_loss: 1.5074 - val_accuracy: 0.5575\n",
      "Epoch 564/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4581 - accuracy: 0.5115 - val_loss: 1.5121 - val_accuracy: 0.5044\n",
      "Epoch 565/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4375 - accuracy: 0.4796 - val_loss: 1.4905 - val_accuracy: 0.4867\n",
      "Epoch 566/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4831 - accuracy: 0.4920 - val_loss: 1.5226 - val_accuracy: 0.4956\n",
      "Epoch 567/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4093 - accuracy: 0.5186 - val_loss: 1.4893 - val_accuracy: 0.4867\n",
      "Epoch 568/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4479 - accuracy: 0.5097 - val_loss: 1.5183 - val_accuracy: 0.5044\n",
      "Epoch 569/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4083 - accuracy: 0.5062 - val_loss: 1.4856 - val_accuracy: 0.5487\n",
      "Epoch 570/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4735 - accuracy: 0.4850 - val_loss: 1.5102 - val_accuracy: 0.5752\n",
      "Epoch 571/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3951 - accuracy: 0.5062 - val_loss: 1.4415 - val_accuracy: 0.4956\n",
      "Epoch 572/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3845 - accuracy: 0.5345 - val_loss: 1.4654 - val_accuracy: 0.5044\n",
      "Epoch 573/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3914 - accuracy: 0.5257 - val_loss: 1.4913 - val_accuracy: 0.5487\n",
      "Epoch 574/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4444 - accuracy: 0.5097 - val_loss: 1.4818 - val_accuracy: 0.5310\n",
      "Epoch 575/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4041 - accuracy: 0.5327 - val_loss: 1.4746 - val_accuracy: 0.5221\n",
      "Epoch 576/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3881 - accuracy: 0.5009 - val_loss: 1.4865 - val_accuracy: 0.5487\n",
      "Epoch 577/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.5204 - val_loss: 1.4386 - val_accuracy: 0.5044\n",
      "Epoch 578/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.5204 - val_loss: 1.4935 - val_accuracy: 0.4867\n",
      "Epoch 579/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3825 - accuracy: 0.4903 - val_loss: 1.4646 - val_accuracy: 0.4956\n",
      "Epoch 580/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3855 - accuracy: 0.5097 - val_loss: 1.4446 - val_accuracy: 0.5221\n",
      "Epoch 581/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3595 - accuracy: 0.5133 - val_loss: 1.4811 - val_accuracy: 0.5221\n",
      "Epoch 582/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4368 - accuracy: 0.5009 - val_loss: 1.4859 - val_accuracy: 0.5310\n",
      "Epoch 583/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3433 - accuracy: 0.5381 - val_loss: 1.4709 - val_accuracy: 0.5310\n",
      "Epoch 584/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3901 - accuracy: 0.5204 - val_loss: 1.4548 - val_accuracy: 0.5133\n",
      "Epoch 585/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3558 - accuracy: 0.5292 - val_loss: 1.4464 - val_accuracy: 0.6106\n",
      "Epoch 586/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3809 - accuracy: 0.5027 - val_loss: 1.4087 - val_accuracy: 0.5575\n",
      "Epoch 587/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4023 - accuracy: 0.5451 - val_loss: 1.4692 - val_accuracy: 0.5487\n",
      "Epoch 588/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3837 - accuracy: 0.5027 - val_loss: 1.4712 - val_accuracy: 0.5044\n",
      "Epoch 589/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3436 - accuracy: 0.5434 - val_loss: 1.4312 - val_accuracy: 0.5487\n",
      "Epoch 590/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3489 - accuracy: 0.5133 - val_loss: 1.4569 - val_accuracy: 0.5310\n",
      "Epoch 591/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3260 - accuracy: 0.5788 - val_loss: 1.4312 - val_accuracy: 0.5841\n",
      "Epoch 592/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3395 - accuracy: 0.5327 - val_loss: 1.4218 - val_accuracy: 0.5929\n",
      "Epoch 593/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3436 - accuracy: 0.5558 - val_loss: 1.3982 - val_accuracy: 0.5310\n",
      "Epoch 594/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3510 - accuracy: 0.5204 - val_loss: 1.3916 - val_accuracy: 0.5841\n",
      "Epoch 595/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2841 - accuracy: 0.5699 - val_loss: 1.3748 - val_accuracy: 0.6195\n",
      "Epoch 596/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3439 - accuracy: 0.5522 - val_loss: 1.3916 - val_accuracy: 0.5752\n",
      "Epoch 597/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3536 - accuracy: 0.5469 - val_loss: 1.4437 - val_accuracy: 0.5133\n",
      "Epoch 598/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2945 - accuracy: 0.5381 - val_loss: 1.4275 - val_accuracy: 0.5487\n",
      "Epoch 599/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3162 - accuracy: 0.5363 - val_loss: 1.4095 - val_accuracy: 0.5310\n",
      "Epoch 600/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3058 - accuracy: 0.5504 - val_loss: 1.4407 - val_accuracy: 0.5664\n",
      "Epoch 601/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2997 - accuracy: 0.5628 - val_loss: 1.3691 - val_accuracy: 0.6018\n",
      "Epoch 602/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3241 - accuracy: 0.5274 - val_loss: 1.3964 - val_accuracy: 0.5841\n",
      "Epoch 603/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3033 - accuracy: 0.5522 - val_loss: 1.3625 - val_accuracy: 0.5841\n",
      "Epoch 604/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3236 - accuracy: 0.5540 - val_loss: 1.4074 - val_accuracy: 0.5752\n",
      "Epoch 605/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2953 - accuracy: 0.5434 - val_loss: 1.3419 - val_accuracy: 0.6106\n",
      "Epoch 606/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2908 - accuracy: 0.5504 - val_loss: 1.4083 - val_accuracy: 0.6018\n",
      "Epoch 607/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3086 - accuracy: 0.5469 - val_loss: 1.3925 - val_accuracy: 0.5487\n",
      "Epoch 608/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2952 - accuracy: 0.5381 - val_loss: 1.4052 - val_accuracy: 0.5841\n",
      "Epoch 609/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3023 - accuracy: 0.5469 - val_loss: 1.4170 - val_accuracy: 0.6018\n",
      "Epoch 610/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3101 - accuracy: 0.5310 - val_loss: 1.3881 - val_accuracy: 0.5487\n",
      "Epoch 611/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2656 - accuracy: 0.5611 - val_loss: 1.3902 - val_accuracy: 0.6106\n",
      "Epoch 612/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2956 - accuracy: 0.5681 - val_loss: 1.3911 - val_accuracy: 0.6106\n",
      "Epoch 613/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2312 - accuracy: 0.5575 - val_loss: 1.3785 - val_accuracy: 0.6106\n",
      "Epoch 614/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2250 - accuracy: 0.5805 - val_loss: 1.3692 - val_accuracy: 0.6018\n",
      "Epoch 615/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2450 - accuracy: 0.5752 - val_loss: 1.3784 - val_accuracy: 0.6106\n",
      "Epoch 616/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2891 - accuracy: 0.5504 - val_loss: 1.3506 - val_accuracy: 0.5929\n",
      "Epoch 617/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2249 - accuracy: 0.5770 - val_loss: 1.3214 - val_accuracy: 0.6018\n",
      "Epoch 618/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2226 - accuracy: 0.5717 - val_loss: 1.3406 - val_accuracy: 0.6106\n",
      "Epoch 619/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2162 - accuracy: 0.5699 - val_loss: 1.2870 - val_accuracy: 0.6372\n",
      "Epoch 620/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2186 - accuracy: 0.5929 - val_loss: 1.3244 - val_accuracy: 0.5841\n",
      "Epoch 621/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2661 - accuracy: 0.5451 - val_loss: 1.3307 - val_accuracy: 0.6106\n",
      "Epoch 622/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1949 - accuracy: 0.6018 - val_loss: 1.3585 - val_accuracy: 0.6460\n",
      "Epoch 623/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2274 - accuracy: 0.5876 - val_loss: 1.3643 - val_accuracy: 0.6372\n",
      "Epoch 624/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2645 - accuracy: 0.5858 - val_loss: 1.3463 - val_accuracy: 0.6018\n",
      "Epoch 625/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1888 - accuracy: 0.6000 - val_loss: 1.3346 - val_accuracy: 0.6106\n",
      "Epoch 626/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2189 - accuracy: 0.5752 - val_loss: 1.2972 - val_accuracy: 0.6018\n",
      "Epoch 627/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1935 - accuracy: 0.6124 - val_loss: 1.3324 - val_accuracy: 0.6106\n",
      "Epoch 628/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1927 - accuracy: 0.6124 - val_loss: 1.3534 - val_accuracy: 0.5664\n",
      "Epoch 629/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1926 - accuracy: 0.5752 - val_loss: 1.3008 - val_accuracy: 0.6195\n",
      "Epoch 630/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2498 - accuracy: 0.5858 - val_loss: 1.3076 - val_accuracy: 0.6106\n",
      "Epoch 631/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2204 - accuracy: 0.5876 - val_loss: 1.2876 - val_accuracy: 0.6460\n",
      "Epoch 632/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2423 - accuracy: 0.5681 - val_loss: 1.2926 - val_accuracy: 0.6283\n",
      "Epoch 633/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2439 - accuracy: 0.5912 - val_loss: 1.3305 - val_accuracy: 0.6283\n",
      "Epoch 634/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2037 - accuracy: 0.6000 - val_loss: 1.3030 - val_accuracy: 0.6372\n",
      "Epoch 635/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1790 - accuracy: 0.6124 - val_loss: 1.3197 - val_accuracy: 0.6195\n",
      "Epoch 636/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1482 - accuracy: 0.6124 - val_loss: 1.2855 - val_accuracy: 0.6195\n",
      "Epoch 637/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1616 - accuracy: 0.5929 - val_loss: 1.2464 - val_accuracy: 0.6460\n",
      "Epoch 638/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1813 - accuracy: 0.6018 - val_loss: 1.2672 - val_accuracy: 0.6372\n",
      "Epoch 639/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1581 - accuracy: 0.6230 - val_loss: 1.2939 - val_accuracy: 0.5841\n",
      "Epoch 640/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1733 - accuracy: 0.6230 - val_loss: 1.2745 - val_accuracy: 0.6460\n",
      "Epoch 641/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1636 - accuracy: 0.6018 - val_loss: 1.3076 - val_accuracy: 0.6195\n",
      "Epoch 642/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1857 - accuracy: 0.6319 - val_loss: 1.2503 - val_accuracy: 0.6372\n",
      "Epoch 643/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1748 - accuracy: 0.6088 - val_loss: 1.2367 - val_accuracy: 0.6814\n",
      "Epoch 644/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1806 - accuracy: 0.6035 - val_loss: 1.2608 - val_accuracy: 0.6372\n",
      "Epoch 645/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1725 - accuracy: 0.6195 - val_loss: 1.2341 - val_accuracy: 0.6814\n",
      "Epoch 646/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1542 - accuracy: 0.6283 - val_loss: 1.2760 - val_accuracy: 0.6195\n",
      "Epoch 647/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1362 - accuracy: 0.6336 - val_loss: 1.2701 - val_accuracy: 0.6372\n",
      "Epoch 648/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1530 - accuracy: 0.5894 - val_loss: 1.2718 - val_accuracy: 0.6195\n",
      "Epoch 649/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1386 - accuracy: 0.6230 - val_loss: 1.2559 - val_accuracy: 0.6460\n",
      "Epoch 650/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1835 - accuracy: 0.6035 - val_loss: 1.2273 - val_accuracy: 0.6372\n",
      "Epoch 651/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1621 - accuracy: 0.6124 - val_loss: 1.2833 - val_accuracy: 0.6903\n",
      "Epoch 652/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1707 - accuracy: 0.6177 - val_loss: 1.2862 - val_accuracy: 0.6637\n",
      "Epoch 653/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1668 - accuracy: 0.6018 - val_loss: 1.3430 - val_accuracy: 0.6106\n",
      "Epoch 654/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1753 - accuracy: 0.6071 - val_loss: 1.3480 - val_accuracy: 0.6018\n",
      "Epoch 655/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.6000 - val_loss: 1.3207 - val_accuracy: 0.6372\n",
      "Epoch 656/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2028 - accuracy: 0.6000 - val_loss: 1.3318 - val_accuracy: 0.6372\n",
      "Epoch 657/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1693 - accuracy: 0.6230 - val_loss: 1.3192 - val_accuracy: 0.6726\n",
      "Epoch 658/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1678 - accuracy: 0.6124 - val_loss: 1.2354 - val_accuracy: 0.6991\n",
      "Epoch 659/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1709 - accuracy: 0.5912 - val_loss: 1.2871 - val_accuracy: 0.6460\n",
      "Epoch 660/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1554 - accuracy: 0.6283 - val_loss: 1.2460 - val_accuracy: 0.6460\n",
      "Epoch 661/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0550 - accuracy: 0.6619 - val_loss: 1.2918 - val_accuracy: 0.6460\n",
      "Epoch 662/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.6602 - val_loss: 1.2430 - val_accuracy: 0.6637\n",
      "Epoch 663/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1313 - accuracy: 0.6177 - val_loss: 1.3089 - val_accuracy: 0.6726\n",
      "Epoch 664/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.6319 - val_loss: 1.2788 - val_accuracy: 0.6106\n",
      "Epoch 665/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1007 - accuracy: 0.6071 - val_loss: 1.3003 - val_accuracy: 0.6814\n",
      "Epoch 666/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0961 - accuracy: 0.6301 - val_loss: 1.3195 - val_accuracy: 0.6460\n",
      "Epoch 667/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.6354 - val_loss: 1.2836 - val_accuracy: 0.6460\n",
      "Epoch 668/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1039 - accuracy: 0.6177 - val_loss: 1.2473 - val_accuracy: 0.6372\n",
      "Epoch 669/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.6496 - val_loss: 1.2242 - val_accuracy: 0.6991\n",
      "Epoch 670/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1064 - accuracy: 0.6354 - val_loss: 1.2535 - val_accuracy: 0.6637\n",
      "Epoch 671/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1063 - accuracy: 0.6319 - val_loss: 1.2514 - val_accuracy: 0.6903\n",
      "Epoch 672/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1283 - accuracy: 0.6159 - val_loss: 1.2502 - val_accuracy: 0.7080\n",
      "Epoch 673/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1129 - accuracy: 0.6354 - val_loss: 1.2027 - val_accuracy: 0.7257\n",
      "Epoch 674/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0968 - accuracy: 0.6230 - val_loss: 1.2068 - val_accuracy: 0.6991\n",
      "Epoch 675/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.6531 - val_loss: 1.2631 - val_accuracy: 0.7257\n",
      "Epoch 676/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0997 - accuracy: 0.6496 - val_loss: 1.2273 - val_accuracy: 0.6903\n",
      "Epoch 677/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0224 - accuracy: 0.6584 - val_loss: 1.2258 - val_accuracy: 0.6549\n",
      "Epoch 678/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.6478 - val_loss: 1.2081 - val_accuracy: 0.6903\n",
      "Epoch 679/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0647 - accuracy: 0.6265 - val_loss: 1.2276 - val_accuracy: 0.6814\n",
      "Epoch 680/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.6372 - val_loss: 1.2438 - val_accuracy: 0.6726\n",
      "Epoch 681/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0292 - accuracy: 0.6549 - val_loss: 1.1824 - val_accuracy: 0.6991\n",
      "Epoch 682/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.6796 - val_loss: 1.1910 - val_accuracy: 0.7080\n",
      "Epoch 683/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0507 - accuracy: 0.6531 - val_loss: 1.1813 - val_accuracy: 0.7168\n",
      "Epoch 684/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0787 - accuracy: 0.6265 - val_loss: 1.2259 - val_accuracy: 0.6814\n",
      "Epoch 685/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0248 - accuracy: 0.6726 - val_loss: 1.2397 - val_accuracy: 0.6991\n",
      "Epoch 686/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.6655 - val_loss: 1.1941 - val_accuracy: 0.7080\n",
      "Epoch 687/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0977 - accuracy: 0.6248 - val_loss: 1.1991 - val_accuracy: 0.6991\n",
      "Epoch 688/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0640 - accuracy: 0.6389 - val_loss: 1.1687 - val_accuracy: 0.7168\n",
      "Epoch 689/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.6425 - val_loss: 1.2445 - val_accuracy: 0.6549\n",
      "Epoch 690/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.6673 - val_loss: 1.1831 - val_accuracy: 0.6991\n",
      "Epoch 691/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.6637 - val_loss: 1.2090 - val_accuracy: 0.6460\n",
      "Epoch 692/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0608 - accuracy: 0.6442 - val_loss: 1.1992 - val_accuracy: 0.7345\n",
      "Epoch 693/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0435 - accuracy: 0.6619 - val_loss: 1.2017 - val_accuracy: 0.6991\n",
      "Epoch 694/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0235 - accuracy: 0.6425 - val_loss: 1.1895 - val_accuracy: 0.6814\n",
      "Epoch 695/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0313 - accuracy: 0.6566 - val_loss: 1.1899 - val_accuracy: 0.7080\n",
      "Epoch 696/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0621 - accuracy: 0.6602 - val_loss: 1.2247 - val_accuracy: 0.6460\n",
      "Epoch 697/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.6690 - val_loss: 1.1985 - val_accuracy: 0.7168\n",
      "Epoch 698/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.6867 - val_loss: 1.1712 - val_accuracy: 0.7168\n",
      "Epoch 699/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0240 - accuracy: 0.6637 - val_loss: 1.2208 - val_accuracy: 0.7257\n",
      "Epoch 700/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0012 - accuracy: 0.6938 - val_loss: 1.1922 - val_accuracy: 0.6814\n",
      "Epoch 701/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0359 - accuracy: 0.6442 - val_loss: 1.2293 - val_accuracy: 0.6549\n",
      "Epoch 702/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0280 - accuracy: 0.6814 - val_loss: 1.1944 - val_accuracy: 0.7257\n",
      "Epoch 703/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0315 - accuracy: 0.6602 - val_loss: 1.1962 - val_accuracy: 0.6991\n",
      "Epoch 704/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.6796 - val_loss: 1.2057 - val_accuracy: 0.7345\n",
      "Epoch 705/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.6690 - val_loss: 1.1697 - val_accuracy: 0.7257\n",
      "Epoch 706/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0097 - accuracy: 0.6637 - val_loss: 1.1664 - val_accuracy: 0.6991\n",
      "Epoch 707/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.6690 - val_loss: 1.1570 - val_accuracy: 0.7168\n",
      "Epoch 708/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0223 - accuracy: 0.6584 - val_loss: 1.1598 - val_accuracy: 0.6991\n",
      "Epoch 709/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9776 - accuracy: 0.6531 - val_loss: 1.1492 - val_accuracy: 0.7345\n",
      "Epoch 710/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.6991 - val_loss: 1.1028 - val_accuracy: 0.7257\n",
      "Epoch 711/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.6708 - val_loss: 1.1726 - val_accuracy: 0.7257\n",
      "Epoch 712/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0284 - accuracy: 0.6743 - val_loss: 1.1789 - val_accuracy: 0.6637\n",
      "Epoch 713/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.6814 - val_loss: 1.1686 - val_accuracy: 0.6726\n",
      "Epoch 714/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.6850 - val_loss: 1.1318 - val_accuracy: 0.7345\n",
      "Epoch 715/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9644 - accuracy: 0.6938 - val_loss: 1.1489 - val_accuracy: 0.7168\n",
      "Epoch 716/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.7204 - val_loss: 1.1408 - val_accuracy: 0.7168\n",
      "Epoch 717/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.6726 - val_loss: 1.1595 - val_accuracy: 0.7257\n",
      "Epoch 718/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9682 - accuracy: 0.7009 - val_loss: 1.1705 - val_accuracy: 0.6903\n",
      "Epoch 719/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9873 - accuracy: 0.6867 - val_loss: 1.1617 - val_accuracy: 0.7611\n",
      "Epoch 720/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9753 - accuracy: 0.6867 - val_loss: 1.1254 - val_accuracy: 0.7168\n",
      "Epoch 721/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.6832 - val_loss: 1.1478 - val_accuracy: 0.6991\n",
      "Epoch 722/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9325 - accuracy: 0.7027 - val_loss: 1.1563 - val_accuracy: 0.7168\n",
      "Epoch 723/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.6903 - val_loss: 1.1529 - val_accuracy: 0.7080\n",
      "Epoch 724/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0237 - accuracy: 0.6761 - val_loss: 1.1482 - val_accuracy: 0.7257\n",
      "Epoch 725/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9619 - accuracy: 0.7009 - val_loss: 1.1240 - val_accuracy: 0.7434\n",
      "Epoch 726/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.7044 - val_loss: 1.1539 - val_accuracy: 0.7345\n",
      "Epoch 727/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9788 - accuracy: 0.6867 - val_loss: 1.1319 - val_accuracy: 0.7168\n",
      "Epoch 728/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9764 - accuracy: 0.6832 - val_loss: 1.2214 - val_accuracy: 0.6726\n",
      "Epoch 729/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.6885 - val_loss: 1.1627 - val_accuracy: 0.7257\n",
      "Epoch 730/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.6956 - val_loss: 1.1487 - val_accuracy: 0.7168\n",
      "Epoch 731/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.7062 - val_loss: 1.1630 - val_accuracy: 0.6991\n",
      "Epoch 732/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.7097 - val_loss: 1.1490 - val_accuracy: 0.7168\n",
      "Epoch 733/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9278 - accuracy: 0.6832 - val_loss: 1.2139 - val_accuracy: 0.6726\n",
      "Epoch 734/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0022 - accuracy: 0.6336 - val_loss: 1.1416 - val_accuracy: 0.7257\n",
      "Epoch 735/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9716 - accuracy: 0.6920 - val_loss: 1.2137 - val_accuracy: 0.6814\n",
      "Epoch 736/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0254 - accuracy: 0.6619 - val_loss: 1.1157 - val_accuracy: 0.7168\n",
      "Epoch 737/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9022 - accuracy: 0.7451 - val_loss: 1.1230 - val_accuracy: 0.7434\n",
      "Epoch 738/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.7274 - val_loss: 1.1791 - val_accuracy: 0.7345\n",
      "Epoch 739/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9368 - accuracy: 0.7009 - val_loss: 1.1545 - val_accuracy: 0.7257\n",
      "Epoch 740/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9335 - accuracy: 0.7080 - val_loss: 1.1420 - val_accuracy: 0.7257\n",
      "Epoch 741/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.7097 - val_loss: 1.1031 - val_accuracy: 0.7434\n",
      "Epoch 742/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9459 - accuracy: 0.7080 - val_loss: 1.1276 - val_accuracy: 0.7699\n",
      "Epoch 743/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.7327 - val_loss: 1.1033 - val_accuracy: 0.7345\n",
      "Epoch 744/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9108 - accuracy: 0.7062 - val_loss: 1.1204 - val_accuracy: 0.7522\n",
      "Epoch 745/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.6761 - val_loss: 1.1554 - val_accuracy: 0.7611\n",
      "Epoch 746/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.7221 - val_loss: 1.1074 - val_accuracy: 0.7257\n",
      "Epoch 747/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.7221 - val_loss: 1.1231 - val_accuracy: 0.7522\n",
      "Epoch 748/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.7292 - val_loss: 1.1491 - val_accuracy: 0.7434\n",
      "Epoch 749/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8339 - accuracy: 0.7363 - val_loss: 1.0724 - val_accuracy: 0.7611\n",
      "Epoch 750/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8719 - accuracy: 0.7363 - val_loss: 1.0770 - val_accuracy: 0.7788\n",
      "Epoch 751/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8715 - accuracy: 0.7292 - val_loss: 1.0941 - val_accuracy: 0.7345\n",
      "Epoch 752/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.7221 - val_loss: 1.0913 - val_accuracy: 0.7788\n",
      "Epoch 753/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8615 - accuracy: 0.7115 - val_loss: 1.1012 - val_accuracy: 0.7699\n",
      "Epoch 754/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.7080 - val_loss: 1.0870 - val_accuracy: 0.7434\n",
      "Epoch 755/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9182 - accuracy: 0.7080 - val_loss: 1.0999 - val_accuracy: 0.7434\n",
      "Epoch 756/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9266 - accuracy: 0.7168 - val_loss: 1.1152 - val_accuracy: 0.7611\n",
      "Epoch 757/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9100 - accuracy: 0.7027 - val_loss: 1.1051 - val_accuracy: 0.7611\n",
      "Epoch 758/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.7133 - val_loss: 1.0690 - val_accuracy: 0.7611\n",
      "Epoch 759/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.7027 - val_loss: 1.0954 - val_accuracy: 0.7788\n",
      "Epoch 760/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.7381 - val_loss: 1.0450 - val_accuracy: 0.7699\n",
      "Epoch 761/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.7451 - val_loss: 1.1200 - val_accuracy: 0.7257\n",
      "Epoch 762/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8483 - accuracy: 0.7327 - val_loss: 1.0456 - val_accuracy: 0.7699\n",
      "Epoch 763/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8765 - accuracy: 0.7239 - val_loss: 1.1072 - val_accuracy: 0.7522\n",
      "Epoch 764/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.7327 - val_loss: 1.0843 - val_accuracy: 0.7876\n",
      "Epoch 765/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.7398 - val_loss: 1.0834 - val_accuracy: 0.7434\n",
      "Epoch 766/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.7080 - val_loss: 1.0729 - val_accuracy: 0.7434\n",
      "Epoch 767/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9052 - accuracy: 0.7204 - val_loss: 1.0891 - val_accuracy: 0.7876\n",
      "Epoch 768/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.7611 - val_loss: 1.0473 - val_accuracy: 0.7699\n",
      "Epoch 769/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8886 - accuracy: 0.7345 - val_loss: 1.0655 - val_accuracy: 0.7699\n",
      "Epoch 770/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8948 - accuracy: 0.7257 - val_loss: 1.0632 - val_accuracy: 0.7611\n",
      "Epoch 771/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8478 - accuracy: 0.7274 - val_loss: 1.0751 - val_accuracy: 0.7876\n",
      "Epoch 772/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9267 - accuracy: 0.7009 - val_loss: 1.0182 - val_accuracy: 0.7788\n",
      "Epoch 773/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8155 - accuracy: 0.7752 - val_loss: 1.0245 - val_accuracy: 0.7965\n",
      "Epoch 774/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8440 - accuracy: 0.7398 - val_loss: 1.0657 - val_accuracy: 0.7611\n",
      "Epoch 775/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.7434 - val_loss: 1.1401 - val_accuracy: 0.7434\n",
      "Epoch 776/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8937 - accuracy: 0.7186 - val_loss: 1.1000 - val_accuracy: 0.7080\n",
      "Epoch 777/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9006 - accuracy: 0.7257 - val_loss: 1.0924 - val_accuracy: 0.7788\n",
      "Epoch 778/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.7292 - val_loss: 1.0924 - val_accuracy: 0.7699\n",
      "Epoch 779/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8278 - accuracy: 0.7345 - val_loss: 1.0733 - val_accuracy: 0.7788\n",
      "Epoch 780/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8432 - accuracy: 0.7416 - val_loss: 1.0852 - val_accuracy: 0.7611\n",
      "Epoch 781/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8514 - accuracy: 0.7310 - val_loss: 1.0518 - val_accuracy: 0.8230\n",
      "Epoch 782/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8287 - accuracy: 0.7504 - val_loss: 1.1156 - val_accuracy: 0.7257\n",
      "Epoch 783/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.7381 - val_loss: 1.0980 - val_accuracy: 0.7611\n",
      "Epoch 784/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8387 - accuracy: 0.7327 - val_loss: 1.0593 - val_accuracy: 0.8053\n",
      "Epoch 785/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8280 - accuracy: 0.7469 - val_loss: 1.1024 - val_accuracy: 0.7611\n",
      "Epoch 786/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8431 - accuracy: 0.7133 - val_loss: 1.0521 - val_accuracy: 0.7876\n",
      "Epoch 787/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.7593 - val_loss: 0.9995 - val_accuracy: 0.7788\n",
      "Epoch 788/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8209 - accuracy: 0.7274 - val_loss: 1.0831 - val_accuracy: 0.7788\n",
      "Epoch 789/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7999 - accuracy: 0.7593 - val_loss: 1.0629 - val_accuracy: 0.7699\n",
      "Epoch 790/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8831 - accuracy: 0.7027 - val_loss: 1.0865 - val_accuracy: 0.7965\n",
      "Epoch 791/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.7292 - val_loss: 1.1082 - val_accuracy: 0.7434\n",
      "Epoch 792/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.7398 - val_loss: 1.0587 - val_accuracy: 0.8053\n",
      "Epoch 793/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.7310 - val_loss: 1.0654 - val_accuracy: 0.7876\n",
      "Epoch 794/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8155 - accuracy: 0.7381 - val_loss: 1.0613 - val_accuracy: 0.7699\n",
      "Epoch 795/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8338 - accuracy: 0.7239 - val_loss: 1.0932 - val_accuracy: 0.7611\n",
      "Epoch 796/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8532 - accuracy: 0.7398 - val_loss: 1.0542 - val_accuracy: 0.7699\n",
      "Epoch 797/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7722 - accuracy: 0.7770 - val_loss: 1.0394 - val_accuracy: 0.7522\n",
      "Epoch 798/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.7593 - val_loss: 1.0346 - val_accuracy: 0.8319\n",
      "Epoch 799/800\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8617 - accuracy: 0.7345 - val_loss: 1.0230 - val_accuracy: 0.8053\n",
      "Epoch 800/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8219 - accuracy: 0.7522 - val_loss: 0.9875 - val_accuracy: 0.8053\n",
      "5/5 [==============================] - 0s 750us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n# Define the model architecture\\nmodel = keras.Sequential([\\n    keras.layers.Dense(128, input_shape=(65,), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\\n    keras.layers.Dropout(0.2),\\n    keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\\n    keras.layers.Dropout(0.2),\\n    keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\\n    keras.layers.Dropout(0.2),\\n    keras.layers.Dense(11, activation='softmax')\\n])\\n\\n# Compile the model\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\n\\n\\n# Fit the model to the data\\nhistory = model.fit(X_train, y_train_one_hot, epochs=500, validation_data=(X_val, y_val_one_hot))#, verbose=0\\n\\n\\n# Evaluate the model on the test set\\ntest_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\\nprint('Test accuracy:', test_acc)\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train_one_hot = lb.fit_transform(y_train)\n",
    "y_test_one_hot = lb.transform(y_test)\n",
    "y_val_one_hot = lb.transform(y_val)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(65,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(11, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train your model\n",
    "#history = model.fit(X_train, y_train_one_hot, batch_size=32, epochs=125, validation_data=(X_test, y_val_one_hot))\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=800, batch_size=32, validation_data=(X_val, y_val_one_hot))\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Select top three diseases\n",
    "top_three = y_pred.argsort()[:, -3:][:, ::-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb1ff656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "#history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b14dc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9782 - accuracy: 0.2817\n",
      "Test loss: 3.978175640106201\n",
      "Test accuracy: 0.28169015049934387\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903144c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c12f316d",
   "metadata": {},
   "source": [
    "### Convert to output for DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96cce8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0                1                      2\n",
      "0         Yellow_Fever             Zika              Tungiasis\n",
      "1               Dengue      Chikungunya                 Plague\n",
      "2          Chikungunya        Tungiasis                 Plague\n",
      "3                 Zika     Yellow_Fever  Japanese_encephalitis\n",
      "4               Plague        Tungiasis                   Zika\n",
      "..                 ...              ...                    ...\n",
      "137       Lyme_disease        Tungiasis                Malaria\n",
      "138  Rift_Valley_fever             Zika        West_Nile_fever\n",
      "139       Yellow_Fever           Dengue                Malaria\n",
      "140             Plague      Chikungunya              Tungiasis\n",
      "141       Yellow_Fever  West_Nile_fever                 Dengue\n",
      "\n",
      "[142 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(top_three)\n",
    "\n",
    "# Define a dictionary that maps the values you want to replace to their replacements\n",
    "replace_dict = {0: 'Lyme_disease', 1: 'Tungiasis', 2: 'Zika', 3: 'Rift_Valley_fever', 4: 'West_Nile_fever', 5: 'Malaria', 6: 'Chikungunya', 7: 'Plague', 8: 'Dengue', 9: 'Yellow_Fever', 10: 'Japanese_encephalitis'}\n",
    "\n",
    "# Use the replace function to replace the values in the DataFrame\n",
    "output_df = output_df.replace(replace_dict)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(output_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cc98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4704040",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2495c",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee827d0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = test_data\n",
    "\n",
    "probabilities = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Get the top 3 classes with the highest probabilities for each example\n",
    "N = 3\n",
    "top_diseases = [probs.argsort()[-N:][::-1] for probs in probabilities]\n",
    "\n",
    "# Map the class indices to their corresponding labels\n",
    "disease_labels = rf_model.classes_\n",
    "top_labels = pd.DataFrame([[disease_labels[i] for i in classes] for classes in top_diseases])\n",
    "# Print the top 3 guesses for the first example\n",
    "#print(top_labels)\n",
    "rect_top_labels = pd.DataFrame(top_labels.apply(lambda row: ' '.join(row.astype(str)), axis=1))\n",
    "\n",
    "\n",
    "output = rect_top_labels.rename(columns={0: 'prognosis'})\n",
    "output['id'] = test_data.id\n",
    "output = output.set_index('id')\n",
    "output\n",
    "#output = pd.DataFrame({'id': test_data.id, 'prognosis': top_labels})\n",
    "\n",
    "\n",
    "output.to_csv('output/output.csv')#, quoting=csv.QUOTE_NONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b57956",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d3717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(rf_model, X, y, cv=10) # k=5\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67f05d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "577fc298",
   "metadata": {},
   "source": [
    "## Conclusion and Road Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5fe81",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69a8bae",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b99b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f3c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f9820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492da4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71772dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
